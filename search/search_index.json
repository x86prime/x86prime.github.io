{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"x86prime A few tools for our x86 subset, x86prime, known as just \"prime\" Prerequisites Install ocaml and opam. This installs the default compiler version for the system, which may not be recent enough. Upgrade this to version 4.07, Then use opam to install menhir and ocamlbuild. On debian based linux this is > sudo apt install ocaml opam > opam init -a On some systems, the default ocaml version is too old. Use \"ocaml --version\" to find which version you have. If you have something before 4.05.0, you need to upgrade. Latest version is 4.07.0. To upgrade do: > opam switch 4.07.0 [at this point you may be asked to run \"eval 'opam config env'\" - do it] You may have to use \"opam switch create\" instead of just \"opam switch\" On some systems, this is not enough, and we recommend that you exit your shell, then restart it before proceeding While OCaml 4.05 works, it produces a lot of warnings. If you'd rather have a clean build process, upgrade to 4.07.0 as described above. > opam install menhir ocamlbuild Building The script \"buildall.sh\" will build 4 tools: primify, a tool which translates real x86 assembler into prime assembler prasm, the assembler, a tool which encodes prime assembler into a format known as \"hex\" prun, a tool which reads hex files and runs them prerf, like prun, but collect performance statistics The tools will be linked from the \"bin\" subdirectory. > ./buildall.sh If by accident you have built part of the program using an old version, you may get an error during build indicating a version problem with part of the project. If this happens, remove the \"_build\" subdirectory. And build again. Generating x86 assembler x86 assembler is in files with suffix \".s\" You can write one yourself. Or generate one from a program written in \"C\" using a C-compiler. > gcc -S -Og -fno-optimize-sibling-calls my_program.c Translating x86 into prime (x86prime) The \"primify\" program will translate an x86 assembler source file into correspondingly named \".prime\" files. > bin/primify my_program.s This results in a new file, \"my_program.prime\" Encoding into hex format The simulators cannot directly read the symbolic prime assembler. You need to assemble it into hex-format. Use > bin/prasm my_program.prime This produces \"my_program.hex\", which can be inspected to learn how the prime program is encoded in numbers. It also produces \"my_program.sym\", which is a list of symbols. This is used by the simulator to allow you to pick which part of the code to execute. Running Programs are simulated by \"prun\" > bin/prun my_program.hex my_start_function Here, the label \"my_start_function\" must have been defined by the original \".prime\" program. Without more options, the simulation is silent. To see what happens, add \"-show\" option Sit back, relax and watch the blinkenlights. Generating a tracefile A tracefile records all changes to memory and register made by your program. You request a tracefile by the \"-tracefile\" option: > bin/prun my_program.s my_start_function -tracefile prog.trc The subdirectory \"examples\" includes an example C program (bubblesort.c) which can be used as introduction to the tools. It has 2 entry-points, \"run\" and \"run2\". If you use \"run\" it will silently input an integer from the keyboard. If running it seems to just hang, try providing a small number and press enter. If you use \"run2\", it will instead try to access any command line arguments. To pass command line arguments into the simulated program, just add them to the command line after all the other arguments. The bubblesort.c program illustrates how the program can access the additional arguments, see the \"run2\" function. Limitations to cross-assembling The translation from x86 to prime is not perfect. When gcc optimizes heavily (\"-O2, -O3\"), the code patterns generated will not be translated correctly. In most cases primify will stop with an exception. We believe \"-Og\" to be working reasonably well, so stick to that. Tail-call optimization will result in code, which cannot be correctly translated into \"prime\", worse: this currently goes undetected - to disable it use \"-fno-optimize-sibling-calls\" When gcc needs to use almost all registers in a function, translation will either fail or just be incorrect. Using combinations of signed and unsigned longs may not be handled correctly. Using constants which cannot be represented in 32-bit 2-complement form may not be handled correctly. Larger \"switch\" statements can not be translated In short, we advise you to check the translation result for correctness instead of blindly trusting it. Performance modelling The \"prerf\" tool runs a program much like \"prun\", but includes a performance model. The model include a selection of branch predictors, a return predictor and 2 configurable levels of cache. It supports 3 different microarchitectures: A simle scalar pipeline. A 3-way in-order superscalar pipeline. A 3-way out-of-order (superscalar) pipeline. There are separate primary caches for instruction and data: Access latency i 3 cycles, fully pipelined. Size 16K, 4-way associative, 32-byte blocks The primary caches are backed by a secondary cache: Access latency 12 cycles (on top of the 3 cycles in L1) Size 128K, 4-way associative, 32-byte blocks The main memory is an additional 100 cycles away. The \"prerf\" tool support generation of execution graphs (da: \"afviklingsplot\"). Some options: \"-show\" display execution graph \"-profile\" display execution profile. Shows the execution count and average execution latency for each instruction. \"-help\" show list of options. Use this to see options for selecting performance model details. \"-print_config\" show configuration of microarchitecture and memory hierachy","title":"Home"},{"location":"#x86prime","text":"A few tools for our x86 subset, x86prime, known as just \"prime\"","title":"x86prime"},{"location":"#prerequisites","text":"Install ocaml and opam. This installs the default compiler version for the system, which may not be recent enough. Upgrade this to version 4.07, Then use opam to install menhir and ocamlbuild. On debian based linux this is > sudo apt install ocaml opam > opam init -a On some systems, the default ocaml version is too old. Use \"ocaml --version\" to find which version you have. If you have something before 4.05.0, you need to upgrade. Latest version is 4.07.0. To upgrade do: > opam switch 4.07.0 [at this point you may be asked to run \"eval 'opam config env'\" - do it] You may have to use \"opam switch create\" instead of just \"opam switch\" On some systems, this is not enough, and we recommend that you exit your shell, then restart it before proceeding While OCaml 4.05 works, it produces a lot of warnings. If you'd rather have a clean build process, upgrade to 4.07.0 as described above. > opam install menhir ocamlbuild","title":"Prerequisites"},{"location":"#building","text":"The script \"buildall.sh\" will build 4 tools: primify, a tool which translates real x86 assembler into prime assembler prasm, the assembler, a tool which encodes prime assembler into a format known as \"hex\" prun, a tool which reads hex files and runs them prerf, like prun, but collect performance statistics The tools will be linked from the \"bin\" subdirectory. > ./buildall.sh If by accident you have built part of the program using an old version, you may get an error during build indicating a version problem with part of the project. If this happens, remove the \"_build\" subdirectory. And build again.","title":"Building"},{"location":"#generating-x86-assembler","text":"x86 assembler is in files with suffix \".s\" You can write one yourself. Or generate one from a program written in \"C\" using a C-compiler. > gcc -S -Og -fno-optimize-sibling-calls my_program.c","title":"Generating x86 assembler"},{"location":"#translating-x86-into-prime-x86prime","text":"The \"primify\" program will translate an x86 assembler source file into correspondingly named \".prime\" files. > bin/primify my_program.s This results in a new file, \"my_program.prime\"","title":"Translating x86 into prime (x86prime)"},{"location":"#encoding-into-hex-format","text":"The simulators cannot directly read the symbolic prime assembler. You need to assemble it into hex-format. Use > bin/prasm my_program.prime This produces \"my_program.hex\", which can be inspected to learn how the prime program is encoded in numbers. It also produces \"my_program.sym\", which is a list of symbols. This is used by the simulator to allow you to pick which part of the code to execute.","title":"Encoding into hex format"},{"location":"#running","text":"Programs are simulated by \"prun\" > bin/prun my_program.hex my_start_function Here, the label \"my_start_function\" must have been defined by the original \".prime\" program. Without more options, the simulation is silent. To see what happens, add \"-show\" option Sit back, relax and watch the blinkenlights.","title":"Running"},{"location":"#generating-a-tracefile","text":"A tracefile records all changes to memory and register made by your program. You request a tracefile by the \"-tracefile\" option: > bin/prun my_program.s my_start_function -tracefile prog.trc The subdirectory \"examples\" includes an example C program (bubblesort.c) which can be used as introduction to the tools. It has 2 entry-points, \"run\" and \"run2\". If you use \"run\" it will silently input an integer from the keyboard. If running it seems to just hang, try providing a small number and press enter. If you use \"run2\", it will instead try to access any command line arguments. To pass command line arguments into the simulated program, just add them to the command line after all the other arguments. The bubblesort.c program illustrates how the program can access the additional arguments, see the \"run2\" function.","title":"Generating a tracefile"},{"location":"#limitations-to-cross-assembling","text":"The translation from x86 to prime is not perfect. When gcc optimizes heavily (\"-O2, -O3\"), the code patterns generated will not be translated correctly. In most cases primify will stop with an exception. We believe \"-Og\" to be working reasonably well, so stick to that. Tail-call optimization will result in code, which cannot be correctly translated into \"prime\", worse: this currently goes undetected - to disable it use \"-fno-optimize-sibling-calls\" When gcc needs to use almost all registers in a function, translation will either fail or just be incorrect. Using combinations of signed and unsigned longs may not be handled correctly. Using constants which cannot be represented in 32-bit 2-complement form may not be handled correctly. Larger \"switch\" statements can not be translated In short, we advise you to check the translation result for correctness instead of blindly trusting it.","title":"Limitations to cross-assembling"},{"location":"#performance-modelling","text":"The \"prerf\" tool runs a program much like \"prun\", but includes a performance model. The model include a selection of branch predictors, a return predictor and 2 configurable levels of cache. It supports 3 different microarchitectures: A simle scalar pipeline. A 3-way in-order superscalar pipeline. A 3-way out-of-order (superscalar) pipeline. There are separate primary caches for instruction and data: Access latency i 3 cycles, fully pipelined. Size 16K, 4-way associative, 32-byte blocks The primary caches are backed by a secondary cache: Access latency 12 cycles (on top of the 3 cycles in L1) Size 128K, 4-way associative, 32-byte blocks The main memory is an additional 100 cycles away. The \"prerf\" tool support generation of execution graphs (da: \"afviklingsplot\"). Some options: \"-show\" display execution graph \"-profile\" display execution profile. Shows the execution count and average execution latency for each instruction. \"-help\" show list of options. Use this to see options for selecting performance model details. \"-print_config\" show configuration of microarchitecture and memory hierachy","title":"Performance modelling"},{"location":"x86prime/","text":"The x86prime instruction set By Finn Schiermer Andersen and Michael Kirkedal Thomsen For students to learn about assembly programming is always hard. It is a significantly different model from what they often know from normal imperative programming (e.g. C, C++, C#). Understanding and working with all the details of X86_64, many of which are there as a reminiscent from old architecture designs, makes this even harder. To simplify this we have designed x86prime. The instruction set x86prime has been designed to be an interesting subset of x86_64, but for parts that are unnecessarily complex (especially conditional jumps) have been inspired mainly RISC5. In the following we will describe the instruction set of x86prime and its difference to x86. However, the following text is not as stand-alone text. It will not describe the detailed semantics of the instructions and we refer to other texts for this. But with a basic knowledge about instructions, you will be safe. Register names The resister names are the expected from x86_64 and the special purpose use are kept, with one noticeable change. we advise not to use %r11 as it is used for procedure calls (see later). %rax , %rbc , %rcx , %rdx , %rbp , %rsi , %rdi , %rsp , %r8 , %r9 , %r10 , %r11 , %r12 , %r13 , %r14 , %r15 . Arithmetic and logical instructions Arithmetic and logical instructions are close following the instructions from x86, that is a binary format where the destination register d is updated (by an operation) with the source register s . That is <op> s,d You can also use a constant ( i ) instead of the source register <op> $i,d Remember the leading $ before the constant. In the above op can be one of the following operations: addq : addition subq : subtraction andq : bitwise and orq : bitwise or xorq : bitwise xor mulq : signed multiplication imulq : unsigned multiplication sarq : shift arithmetic right (preserve topmost bit) salq : shift arithmetic left (zero into lsb, do not preserve topmost bit) shrq : shift (logical) right (zero into topmost bit) Load effective address Load effective address (lea) is a special x86 instruction. It is we was, as the name says, historically meant as an easy way of calculating addresses without reading from memory; hence do pointer arithmetic as in know from C. However, today it is also widely used by compilers do perform standard arithmetic. We have therefore also opted to include it in x86prime. leaq can be used in the following ways: Instruction Semantics Description leaq (s),d s -> d Copy value from register s to register d leaq (,z,v),d z * v -> d Scale register z by v before copy to d leaq (s,z,v),d s + z * v -> d Scale and sum leaq i,d i -> d Get a constant leaq i(s),d i + s -> d Add a constant leaq i(,z,v),d i + z * v -> d Add a constant to a scaled value leaq i(s,z,v),d i + s + z * v -> d Do everything Note v and i are constants while s , d and z are resister names. The scale factors v can only be the constants 1, 2, 4, and 8 Data transfer instructions Like with x86_64 movq are the instruction for loading and storing data. However, x86prime has limited the different ways that is can be used. Instruction Description movq s,d reg->reg copy movq (s),d load (memory -> reg copy) movq d,(s) store (reg -> memory copy) movq $i,d constant -> register movq i(s),d load (memory -> reg copy) movq d,i(s) store (reg -> memory copy) Conditional and unconditional jumps Program flow control is where x86prime diverges significantly from x86_64. We have simply scrapped the concept of branch flags and instead uses conditional branches that includes simple branch expressions as seen in MIPS and RISC5. The most simple of the instructions are the unconditional jump, which follows x86. In the following p is the label at which the execution should continue. jmp p More interesting are the conditional jumps (also called branches). To avoid the branch flags of x86, we will instead use a compare-and-branch instruction. This means that an instruction <cb> takes two values and compares these using a specified two-argument Boolean operator. If this evaluates to true execution will jump to a label p ; otherwise the next instruction will be executed. It can thus be seen a performing a compare followed by a branch instruction in x86. There are two way to give values to a compare-and-branch instruction. Either by comparing the values of two registers s and d <cb> s,d,p or comparing the values of a register d to an intimidate i . <cb> $i,d,p Though the compare-and-branch instruction is not part of the original x86 instruction set, we ensure that the specific conditions in x86prime carry the same meaning as for x86. Thus cbe : Equal cbne : Not equal cbl : less (signed) cble : less or equal (signed) cbg : greater (signed) cbge : greater or equal (signed) cba : above (unsigned) cbae : above or equal (unsigned) cbb : below (unsigned) cbbe : below or equal (unsigned) Note that signed and unsigned comparisons are different. For example, cble %rdi,%rbp,target evaluates if %rdi <= %rbp (signed) then jump to target . Procedural instructions The final instructions of x86prime are the instructions procedure calls. There is one significant difference between these and the similar x86 instructions. Instead of implicitly pushing and popping the return address to/from the stack, the instructions are give a register name in which the return address is handled. Thus call p,d makes a function call to label p and stores the current program counter in register d , while ret s returns from function call, by using the value in register s as the return program counter. As an example a call/return to procedure will have to make sure to store the return address. By convention primify that converts an x86_64 program into an x86prime program uses %r11 for the return address, but a programmer may choose any other register. Thus, when you make procedure calls in x86prime, you will often see the following code. For the call %r11 is added to store the return address: call procedure,%r11 When entering a procedure %r11 is pushed to the call stack and again popped from the stack before the return. This is done to ensure that any usage of %r11 in the procedure body will not overwrite the return address. procedure: subq $8, %rsp movq %r11, (%rsp) <procedure body> movq (%rsp), %r11 addq $8, %rsp ret %r11 Note that x86prime does not have instructions for pushing and popping the stack, so this has to be done by two instructions. Also, if %r11 is not used inside the procedure body, these four instructions can be removed; however this is not done by the current translation. Halting the machine There is a special purpose instruction that halts execution of a x86prime program. This is stop It is not expected to do more than this.","title":"x86prime"},{"location":"x86prime/#the-x86prime-instruction-set","text":"By Finn Schiermer Andersen and Michael Kirkedal Thomsen For students to learn about assembly programming is always hard. It is a significantly different model from what they often know from normal imperative programming (e.g. C, C++, C#). Understanding and working with all the details of X86_64, many of which are there as a reminiscent from old architecture designs, makes this even harder. To simplify this we have designed x86prime. The instruction set x86prime has been designed to be an interesting subset of x86_64, but for parts that are unnecessarily complex (especially conditional jumps) have been inspired mainly RISC5. In the following we will describe the instruction set of x86prime and its difference to x86. However, the following text is not as stand-alone text. It will not describe the detailed semantics of the instructions and we refer to other texts for this. But with a basic knowledge about instructions, you will be safe.","title":"The x86prime instruction set"},{"location":"x86prime/#register-names","text":"The resister names are the expected from x86_64 and the special purpose use are kept, with one noticeable change. we advise not to use %r11 as it is used for procedure calls (see later). %rax , %rbc , %rcx , %rdx , %rbp , %rsi , %rdi , %rsp , %r8 , %r9 , %r10 , %r11 , %r12 , %r13 , %r14 , %r15 .","title":"Register names"},{"location":"x86prime/#arithmetic-and-logical-instructions","text":"Arithmetic and logical instructions are close following the instructions from x86, that is a binary format where the destination register d is updated (by an operation) with the source register s . That is <op> s,d You can also use a constant ( i ) instead of the source register <op> $i,d Remember the leading $ before the constant. In the above op can be one of the following operations: addq : addition subq : subtraction andq : bitwise and orq : bitwise or xorq : bitwise xor mulq : signed multiplication imulq : unsigned multiplication sarq : shift arithmetic right (preserve topmost bit) salq : shift arithmetic left (zero into lsb, do not preserve topmost bit) shrq : shift (logical) right (zero into topmost bit)","title":"Arithmetic and logical instructions"},{"location":"x86prime/#load-effective-address","text":"Load effective address (lea) is a special x86 instruction. It is we was, as the name says, historically meant as an easy way of calculating addresses without reading from memory; hence do pointer arithmetic as in know from C. However, today it is also widely used by compilers do perform standard arithmetic. We have therefore also opted to include it in x86prime. leaq can be used in the following ways: Instruction Semantics Description leaq (s),d s -> d Copy value from register s to register d leaq (,z,v),d z * v -> d Scale register z by v before copy to d leaq (s,z,v),d s + z * v -> d Scale and sum leaq i,d i -> d Get a constant leaq i(s),d i + s -> d Add a constant leaq i(,z,v),d i + z * v -> d Add a constant to a scaled value leaq i(s,z,v),d i + s + z * v -> d Do everything Note v and i are constants while s , d and z are resister names. The scale factors v can only be the constants 1, 2, 4, and 8","title":"Load effective address"},{"location":"x86prime/#data-transfer-instructions","text":"Like with x86_64 movq are the instruction for loading and storing data. However, x86prime has limited the different ways that is can be used. Instruction Description movq s,d reg->reg copy movq (s),d load (memory -> reg copy) movq d,(s) store (reg -> memory copy) movq $i,d constant -> register movq i(s),d load (memory -> reg copy) movq d,i(s) store (reg -> memory copy)","title":"Data transfer instructions"},{"location":"x86prime/#conditional-and-unconditional-jumps","text":"Program flow control is where x86prime diverges significantly from x86_64. We have simply scrapped the concept of branch flags and instead uses conditional branches that includes simple branch expressions as seen in MIPS and RISC5. The most simple of the instructions are the unconditional jump, which follows x86. In the following p is the label at which the execution should continue. jmp p More interesting are the conditional jumps (also called branches). To avoid the branch flags of x86, we will instead use a compare-and-branch instruction. This means that an instruction <cb> takes two values and compares these using a specified two-argument Boolean operator. If this evaluates to true execution will jump to a label p ; otherwise the next instruction will be executed. It can thus be seen a performing a compare followed by a branch instruction in x86. There are two way to give values to a compare-and-branch instruction. Either by comparing the values of two registers s and d <cb> s,d,p or comparing the values of a register d to an intimidate i . <cb> $i,d,p Though the compare-and-branch instruction is not part of the original x86 instruction set, we ensure that the specific conditions in x86prime carry the same meaning as for x86. Thus cbe : Equal cbne : Not equal cbl : less (signed) cble : less or equal (signed) cbg : greater (signed) cbge : greater or equal (signed) cba : above (unsigned) cbae : above or equal (unsigned) cbb : below (unsigned) cbbe : below or equal (unsigned) Note that signed and unsigned comparisons are different. For example, cble %rdi,%rbp,target evaluates if %rdi <= %rbp (signed) then jump to target .","title":"Conditional and unconditional jumps"},{"location":"x86prime/#procedural-instructions","text":"The final instructions of x86prime are the instructions procedure calls. There is one significant difference between these and the similar x86 instructions. Instead of implicitly pushing and popping the return address to/from the stack, the instructions are give a register name in which the return address is handled. Thus call p,d makes a function call to label p and stores the current program counter in register d , while ret s returns from function call, by using the value in register s as the return program counter. As an example a call/return to procedure will have to make sure to store the return address. By convention primify that converts an x86_64 program into an x86prime program uses %r11 for the return address, but a programmer may choose any other register. Thus, when you make procedure calls in x86prime, you will often see the following code. For the call %r11 is added to store the return address: call procedure,%r11 When entering a procedure %r11 is pushed to the call stack and again popped from the stack before the return. This is done to ensure that any usage of %r11 in the procedure body will not overwrite the return address. procedure: subq $8, %rsp movq %r11, (%rsp) <procedure body> movq (%rsp), %r11 addq $8, %rsp ret %r11 Note that x86prime does not have instructions for pushing and popping the stack, so this has to be done by two instructions. Also, if %r11 is not used inside the procedure body, these four instructions can be removed; however this is not done by the current translation.","title":"Procedural instructions"},{"location":"x86prime/#halting-the-machine","text":"There is a special purpose instruction that halts execution of a x86prime program. This is stop It is not expected to do more than this.","title":"Halting the machine"},{"location":"afviklingsplot/","text":"Afviklings Plot (Execution graph) af Finn Schiermer Andersen og Michael Kirkedal Thomsen, DIKU, 2019 Denne lille note introducerer afviklingsplot. Et afviklingsplot er en idealiseret illustration af hvordan en mikroarkitektur afvikler en str\u00f8m af instruktioner. Men det er ogs\u00e5 et redskab som kan bruges til at bestemme CPI (cycles per instruction), et vigtig m\u00e5l for en mikroarkitekturs ydeevne for en str\u00f8m af instruktioner. (Det andet vigtige m\u00e5l er selvf\u00f8lgelig maskinens clock-frekvens) Vi vil lave en gradvis opbygning og langsomt \u00f8ge kompleksiteten. Dvs. vi starter her med en kort beskrivelse, eksemplificeret p\u00e5 en enkelt-cyklus maskine. Derefter vil vi beskrive, hvordan det fungerer p\u00e5 en simpel pipeline maskine , hvilket vil give en dybere forst\u00e5else. Derefter vil vi bev\u00e6ge os over superskalar arkitekturer til en mere avanceret pipeline mikroarkitektur . Vi vil her ogs\u00e5 stifte bekendtskab med kontrol instruktioner. Id\u00e8 Under afvikling af hver instruktion p\u00e5 en given mikroarkitektur gennemg\u00e5r instruktionen forskellige faser. Et afviklingsplot angiver tidspunktet for hver v\u00e6sentlig fase en instruktion genneml\u00f8ber. Instruktionsstr\u00f8mmen angives yderst til venstre, oppefra og ned. Tiden angives i clock-perioder fra venstre mod h\u00f8jre. Eksempel: Enkelt-cyklus mikroarkitektur Her er for eksempel afviklingen af 4 instruktioner p\u00e5 en enkelt-cyklus (single cycle) mikroarkitektur 0123 movq (r10),r11 X mulq $100,r11 X movq r1,(r10) X subq $1,r10 X Her er kun en enkelt fase, kaldet X for eXecute, da alle instruktioner kan udf\u00f8res p\u00e5 en enkelt clock-periode. Vi har alts\u00e5 den sekventielle model, som den vi forst\u00e5r n\u00e5r vi l\u00e6ser et assembler program; f\u00f8rst indl\u00e6ser vi noget fra hukommelsen, derefter l\u00e6gger vi en v\u00e6rdi til dette, hvorefter vi skriver det tilbage til hukommelsen. Hvis vi \u00f8nsker at finde denne arkitekturs CPI, kan man g\u00f8re dette ved at t\u00e6lle antallet af instruktioner; i ovenst\u00e5ende tilf\u00e6lde alts\u00e5 4 clock perioder for 4 instruktioner, eller en CPI p\u00e5 1. CPI Vi vil hele vejen gennem bruge CPI, som et m\u00e5l for ydelsen af et program. CPI st\u00e5r for Clocks cycles Per Instruction, alts\u00e5 et m\u00e5l for hvor mange clock perioder en udf\u00f8rsel af et specifikt program tager. Det kan derfor beregnes ved at t\u00e6lle hvor mange clock perioder det tager for sidste instruktion at blive afsluttet og dele det med antallet af instruktioner. For overst\u00e5ende er det 4 clock perioder delt med 4 instruktioner; alts\u00e5 CPI = 1 , hvilket m\u00e5ske ikke er overraskende. Det er dog vigtigt at notere pr\u00e6cist hvad dette betyder. For det f\u00f8rste siger det meget lidt om hvordan en specifik arkitektur generelt opf\u00f8rer sig. Det udregner CPI for udf\u00f8rslen af et specifikt program, som m\u00e5ske kan representere en klasse af programmer, men man er n\u00f8dt til at have meget stor benchmark af mange forskellige programmer for at sige noget generelt om mikroarkitekturen. For det andet skal man v\u00e6re p\u00e5passelig med sammenligne CPI for et specifikt program mellem forskellige arkitekturer. CPI n\u00e6vner f.eks. ikke noget om l\u00e6ngden p\u00e5 clock perioden. Vi vil stadig g\u00f8re det, men er altid n\u00f8dt til at have overst\u00e5ende med i vores overvejelse. Det er ogs\u00e5 vigtigt et noteret at de plots vi laver starter p\u00e5 hvad vi kan kalde en \"kold\" maskine. Dvs. vores plots vil ikke have nogen instruktioner til at ligge i pipelinen i forvejen. Det kan betyde at is\u00e6r korte programmer vil have en bedre opf\u00f8rsel end hvis vores pipeline var fyldt i forvejen.","title":"Introduktion"},{"location":"afviklingsplot/#afviklings-plot-execution-graph","text":"af Finn Schiermer Andersen og Michael Kirkedal Thomsen, DIKU, 2019 Denne lille note introducerer afviklingsplot. Et afviklingsplot er en idealiseret illustration af hvordan en mikroarkitektur afvikler en str\u00f8m af instruktioner. Men det er ogs\u00e5 et redskab som kan bruges til at bestemme CPI (cycles per instruction), et vigtig m\u00e5l for en mikroarkitekturs ydeevne for en str\u00f8m af instruktioner. (Det andet vigtige m\u00e5l er selvf\u00f8lgelig maskinens clock-frekvens) Vi vil lave en gradvis opbygning og langsomt \u00f8ge kompleksiteten. Dvs. vi starter her med en kort beskrivelse, eksemplificeret p\u00e5 en enkelt-cyklus maskine. Derefter vil vi beskrive, hvordan det fungerer p\u00e5 en simpel pipeline maskine , hvilket vil give en dybere forst\u00e5else. Derefter vil vi bev\u00e6ge os over superskalar arkitekturer til en mere avanceret pipeline mikroarkitektur . Vi vil her ogs\u00e5 stifte bekendtskab med kontrol instruktioner.","title":"Afviklings Plot (Execution graph)"},{"location":"afviklingsplot/#ide","text":"Under afvikling af hver instruktion p\u00e5 en given mikroarkitektur gennemg\u00e5r instruktionen forskellige faser. Et afviklingsplot angiver tidspunktet for hver v\u00e6sentlig fase en instruktion genneml\u00f8ber. Instruktionsstr\u00f8mmen angives yderst til venstre, oppefra og ned. Tiden angives i clock-perioder fra venstre mod h\u00f8jre.","title":"Id\u00e8"},{"location":"afviklingsplot/#eksempel-enkelt-cyklus-mikroarkitektur","text":"Her er for eksempel afviklingen af 4 instruktioner p\u00e5 en enkelt-cyklus (single cycle) mikroarkitektur 0123 movq (r10),r11 X mulq $100,r11 X movq r1,(r10) X subq $1,r10 X Her er kun en enkelt fase, kaldet X for eXecute, da alle instruktioner kan udf\u00f8res p\u00e5 en enkelt clock-periode. Vi har alts\u00e5 den sekventielle model, som den vi forst\u00e5r n\u00e5r vi l\u00e6ser et assembler program; f\u00f8rst indl\u00e6ser vi noget fra hukommelsen, derefter l\u00e6gger vi en v\u00e6rdi til dette, hvorefter vi skriver det tilbage til hukommelsen. Hvis vi \u00f8nsker at finde denne arkitekturs CPI, kan man g\u00f8re dette ved at t\u00e6lle antallet af instruktioner; i ovenst\u00e5ende tilf\u00e6lde alts\u00e5 4 clock perioder for 4 instruktioner, eller en CPI p\u00e5 1.","title":"Eksempel: Enkelt-cyklus mikroarkitektur"},{"location":"afviklingsplot/#cpi","text":"Vi vil hele vejen gennem bruge CPI, som et m\u00e5l for ydelsen af et program. CPI st\u00e5r for Clocks cycles Per Instruction, alts\u00e5 et m\u00e5l for hvor mange clock perioder en udf\u00f8rsel af et specifikt program tager. Det kan derfor beregnes ved at t\u00e6lle hvor mange clock perioder det tager for sidste instruktion at blive afsluttet og dele det med antallet af instruktioner. For overst\u00e5ende er det 4 clock perioder delt med 4 instruktioner; alts\u00e5 CPI = 1 , hvilket m\u00e5ske ikke er overraskende. Det er dog vigtigt at notere pr\u00e6cist hvad dette betyder. For det f\u00f8rste siger det meget lidt om hvordan en specifik arkitektur generelt opf\u00f8rer sig. Det udregner CPI for udf\u00f8rslen af et specifikt program, som m\u00e5ske kan representere en klasse af programmer, men man er n\u00f8dt til at have meget stor benchmark af mange forskellige programmer for at sige noget generelt om mikroarkitekturen. For det andet skal man v\u00e6re p\u00e5passelig med sammenligne CPI for et specifikt program mellem forskellige arkitekturer. CPI n\u00e6vner f.eks. ikke noget om l\u00e6ngden p\u00e5 clock perioden. Vi vil stadig g\u00f8re det, men er altid n\u00f8dt til at have overst\u00e5ende med i vores overvejelse. Det er ogs\u00e5 vigtigt et noteret at de plots vi laver starter p\u00e5 hvad vi kan kalde en \"kold\" maskine. Dvs. vores plots vil ikke have nogen instruktioner til at ligge i pipelinen i forvejen. Det kan betyde at is\u00e6r korte programmer vil have en bedre opf\u00f8rsel end hvis vores pipeline var fyldt i forvejen.","title":"CPI"},{"location":"afviklingsplot/anonyme/","text":"Avanceret pipeline, anonyme faser Det er lidt tr\u00e6ls, hvis man skal redeg\u00f8re separat for hver enkelt fase en instruktion genneml\u00f8ber i en moderne mikroarkitektur. Det skyldes at moderne mikroarkitekturer afvikler instruktioner i mange forskellige faser og disse faser kan tage forskellig l\u00e6ngde. L\u00e6ngere pipelines I moderne CMOS er det ikke realistisk at lave et cache-opslag p\u00e5 en enkelt cyklus. Typisk bruges tre cykler, som er fuldt pipelinet. Oftest er det heller ikke muligt at fuldt afkode en instruktion p\u00e5 en enkelt cyklus. For eksempel, i den simple pipeline ventede (stall) vi p\u00e5 at en load instruktion var helt f\u00e6rdig med M fasen f\u00f8r den n\u00e6ste instruktion gik i gang, med denne fase. I en moderne mikroarkitekturer kan vi have flere instruktioner, som er i gang med at l\u00e6se eller skrive. Vi kunne l\u00f8se dette ved at navngive hver enkelt af de ekstra faser der kr\u00e6ves og opskrive regler for hver af dem. Det bliver dog hurtigt meget kompliceret og bliver umuligt at overskue hvis vi pludselig skal holde styr p\u00e5 3 forskellige navne for dele indhentning, 2 for afkodning, 3 for cache adgang osv. Det varer ikke l\u00e6nge f\u00f8r vi l\u00f8ber t\u00f8r for bogstaver. I stedet v\u00e6lger vi en simplere notation. N\u00e5r vi opskriver faserne for en instruktionsklasse kan vi tilf\u00f8je de ekstra anonyme faser som er p\u00e5kr\u00e6vet med - og angive hvor mange instruktioner der kan befinde sig i \"mellemrummet\" mellem to navngivne faser. Vi kan betragte tidligere beskrivelser af begr\u00e6nsninger som specialtilf\u00e6lde, hvor ingen instruktioner m\u00e5 v\u00e6re i anonyme faser, dvs: F-D: 0 , D-X: 0 , X-M: 0 , M-W: 0 . Her forst\u00e5s s\u00e5leds at \" F-D: 0 \" at der ingen instruktioner m\u00e5 v\u00e6re, som har gennemf\u00f8rt fase F, men ikke p\u00e5begyndt D. Med andre ord: Fase D skal f\u00f8lge direkte efter fase F i afviklingsplottet Eksempel 1: Avanceret pipeline Lad os nu definerer en mere avanceret (og realistisk) mikroarkitektur. Lad os f\u00f8rst fasts\u00e6tte begr\u00e6nsningerne p\u00e5 vores instruktioner Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F--D-XW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F--D-XM--W depend(X,a), produce(M+2,b) Skrivning movq b,(a) F--D-XM depend(X,a), depend(M,b) Dataafh\u00e6ngighederne er de samme som tidligere, men den undtagelse at aritmetik instruktionerne, nu ikke har en M fase og derfor producerer deres resultat til i fase X til fase W . Det ses af faserne. Her har vi indsat to anonyme faser - efter F og M for at definerer cache adgang tager i alt 3 clock perioder. P\u00e5 samme m\u00e5de kan vi se at afkodningen i D nu tager 2 clock perioder. Vi kan stadig lave stalls in disse anonyme faser, s\u00e5 det er muligt at der er flere end antallet mellem to givne faser. Ved l\u00e6sning definerer vi at resultatet til b er klar 2 skridt efter Vi kan nu s\u00e6tte de udvidede specifikationer for faserne som Tilg\u00e6ngelige ressourcer: F:2 , D:2 , X:2 , M:1 , W:2 Antal instruktioner under beregning: F-D: 4 , D-X: 2 , M-W: 2 inorder(F,D,X,M,W) Vi har det samme antal ressourcer som i vores superskalar arkitektur, men kan nu have 4 ekstra instruktioner i de anonyme faser mellem F og D ; alts\u00e5 i gang med at blive indhentet. Der er 2 ekstra mellem D og X , samt 2 ekstra mellem M og W . Det er implicit at der ikke kan v\u00e6re nogen mellem X og M da det her kun tager en clock periode at beregne en v\u00e6rdi. Vi sikre stadig at alle faser afvikles in-order. Se f\u00f8lgende eksempel p\u00e5 en k\u00f8rsel af et program; l\u00e6g m\u00e6rke til at vi har to iterationer at en opdatering at et array: 012345678901234567 -- Vigtigste bem\u00e6rkning movq (r10),r11 F--D-XM--W -- produce(M+2,r11) addq $100,r11 F--D-----XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F--D----XM -- depend(M,r11), depend(M,r11) addq $8,r10 F--DDDDD-XW -- produce(X,r10) movq (r10),r11 F--DDDD--XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 F------D-----XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-----DD----XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------DDDDD-XW -- depend(X,r10), produce(X,r10) Nu begynder der at ske en del. instruktion forl\u00f8ber normalt, da vi har en \"tom\" pipeline; dog b\u00f8r noteres at v\u00e6rdien fra l\u00e6sning f\u00f8rst er klar i fase W instruktion kan indl\u00e6ses og afkodes samtidig med den f\u00f8rste; vi har to enheder. Dog er den afh\u00e6ngig af at r11 er klar i X , s\u00e5 denne fase kan tidligst v\u00e6re samtidig med W fra f\u00f8rste instruktion. Vi laver alts\u00e5 en stall i den anonyme afkodningsfase. instruktion kan indl\u00e6ses i anden fra anden periode og afkodning kan g\u00e5 i gang som normalt. Vi har dog damme afh\u00e6ngighed som f\u00f8r of er n\u00f8dt til at stall i D 's - . instruktion kan begynde indl\u00e6sning og afkodning samtidig med den tidligere. Vi har dog allerede fyldt anden del af D , s\u00e5 vi staller denne i D ; se at der allerede er to streger i s\u00f8jlen over efter D . Afh\u00e6ngigheden p\u00e5 r10 er endnu ikke noget problem, men vi noterer at den opdaterer r10 i W fasen. instruktion og vi starter anden iteration. Vi kan begynde indl\u00e6sningen som forventet, men er igen n\u00f8dt til at stalle i D til vi har plads til at afkode. Vi har derefter en afh\u00e6ngighed p\u00e5 r10 i X fasen, som vi s\u00e5 er n\u00f8dt til at stalle en enkelt clock periode. Resten forl\u00f8ber som forventet, men indl\u00e6sning til r11 er f\u00f8rst klar til W . instruktion er vi nu n\u00f8dt til at stalle i indl\u00e6sningen, F , da der ikke er plads i afkodningen. Derefter er vi igen n\u00f8dt til at stalle efter D for at vente p\u00e5 vores afh\u00e6ngighed p\u00e5 r11 ; X kan ikke ligge tidligere en samtidig med W fra f\u00f8r. instruktion er igen en masse stall efter F og derefter D . Vi har f\u00f8rst en afh\u00e6ngig p\u00e5 r10 i X som kommer fra fjerde instruktion; vi har dog en in-order maskine og kan derfor ikke ligge adresseberegningen tidligere end X fra den forrige instruktion. Dette l\u00f8ser ogs\u00e5 afh\u00e6ngigheden p\u00e5 r11 i M , da denne bliver produceret i forrige instruktions W . instruktion forsinkes b\u00e5de i F og D , som tidligere. Ellers er der ikke noget at bem\u00e6rke. Abstraktion, samlet indl\u00e6sning og afkodning Anonyme faser kan ogs\u00e5 g\u00f8re det nemmere at se bort fra ting der ikke har interesse. For eksempel kan vi udelade afkodningstrinnet fra vores beskrivelse, da det altid f\u00f8lger direkte efter indhentning og har samme antal ressourcer. I stedet kan vi lave vores indl\u00e6sningstrin det l\u00e6ngere og f\u00e5 samme afvikling: Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F----XW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F----XM--W depend(X,a), produce(M+2,b) Skrivning movq b,(a) F----XM depend(X,a), depend(M,b) Tilg\u00e6ngelige ressourcer: F:2 , X:2 , M:1 , W:2 Antal instruktioner under beregning: F-X: 8 , M-W: 2 inorder(F,D,X,M,W) Dette giver den samme afvikling, blot er D ikke n\u00e6vnt, men til g\u00e6ng\u00e6ld kan det v\u00e6re mere overskueligt. 012345678901234567 -- Vigtigste bem\u00e6rkning movq (r10),r11 F----XM--W -- produce(M+2,r11) addq $100,r11 F--------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-------XM -- depend(M,r11), depend(M,r11) addq $8,r10 F--------XW -- produce(X,r10) movq (r10),r11 F--------XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 F------------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-----------XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------------XW -- depend(X,r10), produce(X,r10) Bem\u00e6rk i\u00f8vrigt at selvom denne maskine kan h\u00e5ndtere 2 instruktioner per clk, s\u00e5 opn\u00e5r den i ovenst\u00e5ende eksempel 4/9 IPC, dvs. mindre end \u00bd instruktion per clk. Eksempel 2: Mere udrulning Det ser ud til at vi nu bare kan indhente instruktioner, som vi lyster. S\u00e5 n\u00e5r vi nu er s\u00e5 godt i gang, kan vi tage en udrulning mere. 012345678901234567890123 -- Vigtigste bem\u00e6rkning movq (r10),r11 F----XM--W -- produce(M+2,r11) addq $100,r11 F--------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-------XM -- depend(M,r11), depend(M,r11) addq $8,r10 F--------XW -- produce(X,r10) movq (r10),r11 F--------XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 F------------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-----------XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------------XW -- depend(X,r10), produce(X,r10) movq (r10),r11 F------------XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 FFFFF------------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) FFFF------------XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------------XW -- depend(X,r10), produce(X,r10) instruktion kan starte indhentning som normalt. Hvis vi t\u00e6ller antallet af streger over dette F (hold tungen lige i munden) t\u00e6ller vi 8, som er plads til. I den efterf\u00f8lgende periode (nummer 5) forts\u00e6tter f\u00f8rst instruktion til X , s\u00e5 denne instruktion kan forts\u00e6tte sin indl\u00e6sning. S\u00e5 skal vi bare huske vores afh\u00e6ngighed p\u00e5 r10 . instruktion kan starte indhentning med den tidligere. Men nu er de anonyme faser fulde og vi bliver n\u00f8dt til at blive i F . Afslutningen f\u00f8lger de tidligere iterationer. Vi kan starte indl\u00e6sningen i periode 5, men er igen n\u00f8dt til at stalle i F . Nu er F ogs\u00e5 blevet fyldt og vi er n\u00f8dt til forsinke selve indl\u00e6sningen. Det er f\u00f8rst i periode 9 at anden instruktion komme ud af sin indl\u00e6sning og vi kan derfor starte denne. Det man is\u00e6r kan tage med fra ovenst\u00e5ende eksempel, er hvor mange instruktioner, som er i gang med at blive indl\u00e6st og hvor lang tid denne del tager sammenlignet med selve beregningen. K\u00f8er Ofte indg\u00e5r k\u00f8er af instruktioner i en mikroarkitektur. Ikke s\u00e5 tit i en simpel skalar pipeline, men ofte i superskalare pipelines. For eksempel er det ofte en fordel med en k\u00f8 mellem instruktionshentning og afkodning. For maskiner med variabel-l\u00e6ngde instruktioner kan det v\u00e6re n\u00f8dvendigt fordi afkoderen har en begr\u00e6nsning p\u00e5 hvor mange instruktioner den kan h\u00e5ndtere, mens instruktionshentningen har en begr\u00e6nsning udtrykt i bytes eller cache-blokke. Dermed kan man undg\u00e5 at indl\u00e6se samme instruktion flere gange. Dette mis-match aff\u00f8der et behov for at have en eller flere bytes/instruktioner i k\u00f8 mellem de to trin. Vi vil modellerer en k\u00f8 som et antal anonyme faser. For eksempel kan vi udtrykke en k\u00f8 mellem F og D med plads til fire instruktioner som en ressource begr\u00e6nsning: \"F-D: 4\" Cache-miss Vi modellerer lager-hierarkiet ved at holde rede p\u00e5 indholdet af systemets cache(s) instruktion for instruktion. Cache-miss inkluderes i modellen alene derved at det p\u00e5virker latens-tiden for de instruktioner, der l\u00e6ser fra lageret. Dette er en voldsom forsimpling. Vi ser s\u00e5ledes bort fra en r\u00e6kke typiske begr\u00e6nsninger: I en helt simpel pipeline vil man m\u00e5ske fryse selve pipelinen indtil data er ankommet. Det vil have d\u00e5rligere ydeevne, end blot at for\u00f8ge latenstiden, som vi g\u00f8r. Der kan v\u00e6re et begr\u00e6nset antal overlappende l\u00e6sninger i gang samtidigt. Der kan v\u00e6re et begr\u00e6nset antal snavsede blokke som er smidt ud p\u00e5 et niveau af hierarkiet og venter i k\u00f8 p\u00e5 at blive skrevet til det underliggende niveau. Der kan v\u00e6re ressource konflikter ved tilgang til en cache; f.eks. kan man m\u00e5ske ikke l\u00e6se fra cachen, samtidigt med at data der hentes i respons p\u00e5 et tidligere miss ankommer og skrives til cachen. Det ser vi alt sammen bort fra. Der antages copy-back caching med LRU replacement. Kontrolafh\u00e6ngigheder Se Kontrolafh\u00e6ngighed","title":"Avanceret pipeline, anonyme faser"},{"location":"afviklingsplot/anonyme/#avanceret-pipeline-anonyme-faser","text":"Det er lidt tr\u00e6ls, hvis man skal redeg\u00f8re separat for hver enkelt fase en instruktion genneml\u00f8ber i en moderne mikroarkitektur. Det skyldes at moderne mikroarkitekturer afvikler instruktioner i mange forskellige faser og disse faser kan tage forskellig l\u00e6ngde.","title":"Avanceret pipeline, anonyme faser"},{"location":"afviklingsplot/anonyme/#lngere-pipelines","text":"I moderne CMOS er det ikke realistisk at lave et cache-opslag p\u00e5 en enkelt cyklus. Typisk bruges tre cykler, som er fuldt pipelinet. Oftest er det heller ikke muligt at fuldt afkode en instruktion p\u00e5 en enkelt cyklus. For eksempel, i den simple pipeline ventede (stall) vi p\u00e5 at en load instruktion var helt f\u00e6rdig med M fasen f\u00f8r den n\u00e6ste instruktion gik i gang, med denne fase. I en moderne mikroarkitekturer kan vi have flere instruktioner, som er i gang med at l\u00e6se eller skrive. Vi kunne l\u00f8se dette ved at navngive hver enkelt af de ekstra faser der kr\u00e6ves og opskrive regler for hver af dem. Det bliver dog hurtigt meget kompliceret og bliver umuligt at overskue hvis vi pludselig skal holde styr p\u00e5 3 forskellige navne for dele indhentning, 2 for afkodning, 3 for cache adgang osv. Det varer ikke l\u00e6nge f\u00f8r vi l\u00f8ber t\u00f8r for bogstaver. I stedet v\u00e6lger vi en simplere notation. N\u00e5r vi opskriver faserne for en instruktionsklasse kan vi tilf\u00f8je de ekstra anonyme faser som er p\u00e5kr\u00e6vet med - og angive hvor mange instruktioner der kan befinde sig i \"mellemrummet\" mellem to navngivne faser. Vi kan betragte tidligere beskrivelser af begr\u00e6nsninger som specialtilf\u00e6lde, hvor ingen instruktioner m\u00e5 v\u00e6re i anonyme faser, dvs: F-D: 0 , D-X: 0 , X-M: 0 , M-W: 0 . Her forst\u00e5s s\u00e5leds at \" F-D: 0 \" at der ingen instruktioner m\u00e5 v\u00e6re, som har gennemf\u00f8rt fase F, men ikke p\u00e5begyndt D. Med andre ord: Fase D skal f\u00f8lge direkte efter fase F i afviklingsplottet","title":"L\u00e6ngere pipelines"},{"location":"afviklingsplot/anonyme/#eksempel-1-avanceret-pipeline","text":"Lad os nu definerer en mere avanceret (og realistisk) mikroarkitektur. Lad os f\u00f8rst fasts\u00e6tte begr\u00e6nsningerne p\u00e5 vores instruktioner Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F--D-XW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F--D-XM--W depend(X,a), produce(M+2,b) Skrivning movq b,(a) F--D-XM depend(X,a), depend(M,b) Dataafh\u00e6ngighederne er de samme som tidligere, men den undtagelse at aritmetik instruktionerne, nu ikke har en M fase og derfor producerer deres resultat til i fase X til fase W . Det ses af faserne. Her har vi indsat to anonyme faser - efter F og M for at definerer cache adgang tager i alt 3 clock perioder. P\u00e5 samme m\u00e5de kan vi se at afkodningen i D nu tager 2 clock perioder. Vi kan stadig lave stalls in disse anonyme faser, s\u00e5 det er muligt at der er flere end antallet mellem to givne faser. Ved l\u00e6sning definerer vi at resultatet til b er klar 2 skridt efter Vi kan nu s\u00e6tte de udvidede specifikationer for faserne som Tilg\u00e6ngelige ressourcer: F:2 , D:2 , X:2 , M:1 , W:2 Antal instruktioner under beregning: F-D: 4 , D-X: 2 , M-W: 2 inorder(F,D,X,M,W) Vi har det samme antal ressourcer som i vores superskalar arkitektur, men kan nu have 4 ekstra instruktioner i de anonyme faser mellem F og D ; alts\u00e5 i gang med at blive indhentet. Der er 2 ekstra mellem D og X , samt 2 ekstra mellem M og W . Det er implicit at der ikke kan v\u00e6re nogen mellem X og M da det her kun tager en clock periode at beregne en v\u00e6rdi. Vi sikre stadig at alle faser afvikles in-order. Se f\u00f8lgende eksempel p\u00e5 en k\u00f8rsel af et program; l\u00e6g m\u00e6rke til at vi har to iterationer at en opdatering at et array: 012345678901234567 -- Vigtigste bem\u00e6rkning movq (r10),r11 F--D-XM--W -- produce(M+2,r11) addq $100,r11 F--D-----XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F--D----XM -- depend(M,r11), depend(M,r11) addq $8,r10 F--DDDDD-XW -- produce(X,r10) movq (r10),r11 F--DDDD--XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 F------D-----XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-----DD----XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------DDDDD-XW -- depend(X,r10), produce(X,r10) Nu begynder der at ske en del. instruktion forl\u00f8ber normalt, da vi har en \"tom\" pipeline; dog b\u00f8r noteres at v\u00e6rdien fra l\u00e6sning f\u00f8rst er klar i fase W instruktion kan indl\u00e6ses og afkodes samtidig med den f\u00f8rste; vi har to enheder. Dog er den afh\u00e6ngig af at r11 er klar i X , s\u00e5 denne fase kan tidligst v\u00e6re samtidig med W fra f\u00f8rste instruktion. Vi laver alts\u00e5 en stall i den anonyme afkodningsfase. instruktion kan indl\u00e6ses i anden fra anden periode og afkodning kan g\u00e5 i gang som normalt. Vi har dog damme afh\u00e6ngighed som f\u00f8r of er n\u00f8dt til at stall i D 's - . instruktion kan begynde indl\u00e6sning og afkodning samtidig med den tidligere. Vi har dog allerede fyldt anden del af D , s\u00e5 vi staller denne i D ; se at der allerede er to streger i s\u00f8jlen over efter D . Afh\u00e6ngigheden p\u00e5 r10 er endnu ikke noget problem, men vi noterer at den opdaterer r10 i W fasen. instruktion og vi starter anden iteration. Vi kan begynde indl\u00e6sningen som forventet, men er igen n\u00f8dt til at stalle i D til vi har plads til at afkode. Vi har derefter en afh\u00e6ngighed p\u00e5 r10 i X fasen, som vi s\u00e5 er n\u00f8dt til at stalle en enkelt clock periode. Resten forl\u00f8ber som forventet, men indl\u00e6sning til r11 er f\u00f8rst klar til W . instruktion er vi nu n\u00f8dt til at stalle i indl\u00e6sningen, F , da der ikke er plads i afkodningen. Derefter er vi igen n\u00f8dt til at stalle efter D for at vente p\u00e5 vores afh\u00e6ngighed p\u00e5 r11 ; X kan ikke ligge tidligere en samtidig med W fra f\u00f8r. instruktion er igen en masse stall efter F og derefter D . Vi har f\u00f8rst en afh\u00e6ngig p\u00e5 r10 i X som kommer fra fjerde instruktion; vi har dog en in-order maskine og kan derfor ikke ligge adresseberegningen tidligere end X fra den forrige instruktion. Dette l\u00f8ser ogs\u00e5 afh\u00e6ngigheden p\u00e5 r11 i M , da denne bliver produceret i forrige instruktions W . instruktion forsinkes b\u00e5de i F og D , som tidligere. Ellers er der ikke noget at bem\u00e6rke.","title":"Eksempel 1: Avanceret pipeline"},{"location":"afviklingsplot/anonyme/#abstraktion-samlet-indlsning-og-afkodning","text":"Anonyme faser kan ogs\u00e5 g\u00f8re det nemmere at se bort fra ting der ikke har interesse. For eksempel kan vi udelade afkodningstrinnet fra vores beskrivelse, da det altid f\u00f8lger direkte efter indhentning og har samme antal ressourcer. I stedet kan vi lave vores indl\u00e6sningstrin det l\u00e6ngere og f\u00e5 samme afvikling: Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F----XW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F----XM--W depend(X,a), produce(M+2,b) Skrivning movq b,(a) F----XM depend(X,a), depend(M,b) Tilg\u00e6ngelige ressourcer: F:2 , X:2 , M:1 , W:2 Antal instruktioner under beregning: F-X: 8 , M-W: 2 inorder(F,D,X,M,W) Dette giver den samme afvikling, blot er D ikke n\u00e6vnt, men til g\u00e6ng\u00e6ld kan det v\u00e6re mere overskueligt. 012345678901234567 -- Vigtigste bem\u00e6rkning movq (r10),r11 F----XM--W -- produce(M+2,r11) addq $100,r11 F--------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-------XM -- depend(M,r11), depend(M,r11) addq $8,r10 F--------XW -- produce(X,r10) movq (r10),r11 F--------XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 F------------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-----------XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------------XW -- depend(X,r10), produce(X,r10) Bem\u00e6rk i\u00f8vrigt at selvom denne maskine kan h\u00e5ndtere 2 instruktioner per clk, s\u00e5 opn\u00e5r den i ovenst\u00e5ende eksempel 4/9 IPC, dvs. mindre end \u00bd instruktion per clk.","title":"Abstraktion, samlet indl\u00e6sning og afkodning"},{"location":"afviklingsplot/anonyme/#eksempel-2-mere-udrulning","text":"Det ser ud til at vi nu bare kan indhente instruktioner, som vi lyster. S\u00e5 n\u00e5r vi nu er s\u00e5 godt i gang, kan vi tage en udrulning mere. 012345678901234567890123 -- Vigtigste bem\u00e6rkning movq (r10),r11 F----XM--W -- produce(M+2,r11) addq $100,r11 F--------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-------XM -- depend(M,r11), depend(M,r11) addq $8,r10 F--------XW -- produce(X,r10) movq (r10),r11 F--------XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 F------------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) F-----------XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------------XW -- depend(X,r10), produce(X,r10) movq (r10),r11 F------------XM--W -- depend(X,r10), produce(M+2,r11) addq $100,r11 FFFFF------------XW -- depend(X,r11), produce(X,r11) movq r11,(r10) FFFF------------XM -- depend(X,r10), depend(M,r11) addq $8,r10 F------------XW -- depend(X,r10), produce(X,r10) instruktion kan starte indhentning som normalt. Hvis vi t\u00e6ller antallet af streger over dette F (hold tungen lige i munden) t\u00e6ller vi 8, som er plads til. I den efterf\u00f8lgende periode (nummer 5) forts\u00e6tter f\u00f8rst instruktion til X , s\u00e5 denne instruktion kan forts\u00e6tte sin indl\u00e6sning. S\u00e5 skal vi bare huske vores afh\u00e6ngighed p\u00e5 r10 . instruktion kan starte indhentning med den tidligere. Men nu er de anonyme faser fulde og vi bliver n\u00f8dt til at blive i F . Afslutningen f\u00f8lger de tidligere iterationer. Vi kan starte indl\u00e6sningen i periode 5, men er igen n\u00f8dt til at stalle i F . Nu er F ogs\u00e5 blevet fyldt og vi er n\u00f8dt til forsinke selve indl\u00e6sningen. Det er f\u00f8rst i periode 9 at anden instruktion komme ud af sin indl\u00e6sning og vi kan derfor starte denne. Det man is\u00e6r kan tage med fra ovenst\u00e5ende eksempel, er hvor mange instruktioner, som er i gang med at blive indl\u00e6st og hvor lang tid denne del tager sammenlignet med selve beregningen.","title":"Eksempel 2: Mere udrulning"},{"location":"afviklingsplot/anonyme/#ker","text":"Ofte indg\u00e5r k\u00f8er af instruktioner i en mikroarkitektur. Ikke s\u00e5 tit i en simpel skalar pipeline, men ofte i superskalare pipelines. For eksempel er det ofte en fordel med en k\u00f8 mellem instruktionshentning og afkodning. For maskiner med variabel-l\u00e6ngde instruktioner kan det v\u00e6re n\u00f8dvendigt fordi afkoderen har en begr\u00e6nsning p\u00e5 hvor mange instruktioner den kan h\u00e5ndtere, mens instruktionshentningen har en begr\u00e6nsning udtrykt i bytes eller cache-blokke. Dermed kan man undg\u00e5 at indl\u00e6se samme instruktion flere gange. Dette mis-match aff\u00f8der et behov for at have en eller flere bytes/instruktioner i k\u00f8 mellem de to trin. Vi vil modellerer en k\u00f8 som et antal anonyme faser. For eksempel kan vi udtrykke en k\u00f8 mellem F og D med plads til fire instruktioner som en ressource begr\u00e6nsning: \"F-D: 4\"","title":"K\u00f8er"},{"location":"afviklingsplot/anonyme/#cache-miss","text":"Vi modellerer lager-hierarkiet ved at holde rede p\u00e5 indholdet af systemets cache(s) instruktion for instruktion. Cache-miss inkluderes i modellen alene derved at det p\u00e5virker latens-tiden for de instruktioner, der l\u00e6ser fra lageret. Dette er en voldsom forsimpling. Vi ser s\u00e5ledes bort fra en r\u00e6kke typiske begr\u00e6nsninger: I en helt simpel pipeline vil man m\u00e5ske fryse selve pipelinen indtil data er ankommet. Det vil have d\u00e5rligere ydeevne, end blot at for\u00f8ge latenstiden, som vi g\u00f8r. Der kan v\u00e6re et begr\u00e6nset antal overlappende l\u00e6sninger i gang samtidigt. Der kan v\u00e6re et begr\u00e6nset antal snavsede blokke som er smidt ud p\u00e5 et niveau af hierarkiet og venter i k\u00f8 p\u00e5 at blive skrevet til det underliggende niveau. Der kan v\u00e6re ressource konflikter ved tilgang til en cache; f.eks. kan man m\u00e5ske ikke l\u00e6se fra cachen, samtidigt med at data der hentes i respons p\u00e5 et tidligere miss ankommer og skrives til cachen. Det ser vi alt sammen bort fra. Der antages copy-back caching med LRU replacement.","title":"Cache-miss"},{"location":"afviklingsplot/anonyme/#kontrolafhngigheder","text":"Se Kontrolafh\u00e6ngighed","title":"Kontrolafh\u00e6ngigheder"},{"location":"afviklingsplot/kontrol/","text":"Kontrol afh\u00e6ngigheder Modellering Vi modellerer effekten af hop, kald og retur ved at forsinke F . For kald og retur skelner vi mellem korrekte og fejlagtige forudsigelser. For betingede hop skelner vi tillige mellem om hoppet tages eller ej. Vi udtrykker effekten ved tildelinger til en ny tidsvariabel: NextF.time Og for enhver instruktion g\u00e6lder altid at F.time >= NextF.time Vi tilf\u00f8jer en ny fase, B , specifik for betingede hop, kald og retur. B svarer til X for de aritmetiske instruktioner. B angiver det tidspunkt, hvor vi afg\u00f8r om forudsigelser af instruktionen var korrekt eller ej. Vi tillader at B indtr\u00e6ffer out-of-order i forhold til andre typer instruktioner, men kr\u00e6ver det sker in-order i forhold til andre hop, kald eller retur. call a,b: F----QBC ret a: F----QBC cbcc a,b,x: F----QBC inorder(B) Her er nogle mulige regler for en out-of-order maskine som beskrevet ovenfor Instruktion Taget Forudsagt Effekt Call ja ja produce(F+2,pc) Ret ja ja produce(F+2,pc) ja nej produce(B+1,pc) CBcc nej ja - (ikke muligt) nej nej produce(B+1,pc) ja ja produce(F+2,pc) ja nej produce(F+2,pc) Husk at pc er vores specielle register til at pege p\u00e5 n\u00e6ste instruktion, s\u00e5 ovenst\u00e5ende peger p\u00e5 hvor hurtigt n\u00e6ste instruktion kan v\u00e6re klar. Herunder ses to genneml\u00f8b af en indre l\u00f8kke, hvor hop forudsiges korrekt. 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C -- produce(F+2, pc) (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C Ydeevne: 5/4 IPC. L\u00e6g m\u00e6rke til at hoppet i denne eksekvering bliver taget korrekt og n\u00e6ste instruktion bliver derfor kun forsinket 2 clock perioder. P\u00e5 grund af omkostningen ved hop vil en overs\u00e6tter ofte rulle en l\u00f8kke-krop ud en eller flere gange. Herunder ses effekten af en enkelt udrulning 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbgt r10,r12,exit F----QB----C -- forudsagt korrekt ikke taget movq (r10),r11 F----QAM---C -- depend(A,r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C -- produce(F+2, pc) (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) Ydeevne: 10/6 IPC En anden teknik til at skjule omkostningen ved tagne hop er at man dimensionerer forenden af mikroarkitektur ( F til Q ) lidt st\u00f8rre end resten. Her er for eksempel et afviklingsplot for den ikke udrullede l\u00f8kke p\u00e5 en maskine der kan h\u00e5ndtere 3 instruktioner samtidigt i F til Q : 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----Q-AM--VC -- depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----Q-B----C -- produce(F+2, pc) (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C -- depends(A, r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----Q-AM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----Q-B----C Ydeevne: 5/3 IPC Her ses effekten af en forkert forudsigelse: 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C -- produce(B+1, pc) loop: movq (r10),r11 F----QAM--C -- depends(A, r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) Ydeevne 5/9 IPC Jo l\u00e6ngere pipeline, jo st\u00f8rre omkostning ved forkerte forudsigelser. spekulativ udf\u00f8relse Det kan ske at B fasen indtr\u00e6ffer meget sent i forhold til udf\u00f8relsen af andre instruktioner. Betragt for eksempel nedenst\u00e5ende stump kode long v = tab[j]; if (v > key) { *ptr = *ptr + 1; // found it! } Oversat til x86prime kan det blive til f\u00f8lgende programstump: movq (r10,r11,8),r12 cble r12,r13,.endif movq (r15),r14 addq $1,r14 movq r14,(r15) .endif: og lad os antage at variablen tab befinder sig i L2-cache, mens omr\u00e5det udpeget af variablen ptr er i L1-cache. Lad os antage at L2-cache tilgang koster 10 cykler (oveni L1-tilgang). 01234567890123456789012 movq (r10,r11,8),r12 F----QAM------------C cble r12,r13,else F----Q--------------BC movq (r15),r14 F----QAM------------C addq $1,r14 F----Q----X----------C movq r14,(r15) F----QAM--V---------C Det betingede hop afh\u00e6nger af en instruktion der er n\u00f8d til at hente en v\u00e6rdi i L2 og bliver s\u00e5ledes forsinket s\u00e5 det f\u00f8rst kan afg\u00f8res i cyklus 20. Hoppet er forudsagt \"ikke taget\" og f\u00f8r det afg\u00f8res kan de n\u00e6ste tre instruktioner l\u00e6se fra L1-cachen, beregne en ny v\u00e6rdi og l\u00e6gge den i k\u00f8 til skrivning til L1. Det g\u00e5r selvsagt ikke an faktisk at opdatere L1, f\u00f8r vi ved om hoppet er forudsagt korrekt, men alle \u00f8vrige aktiviteter kan gennemf\u00f8res. De instruktioner som udf\u00f8res tidligere end et eller flere hop, kald eller retur, som de egentlig afh\u00e6nger af, siges at v\u00e6re spekulativt udf\u00f8rt. Spekulativ udf\u00f8relse fjerner en v\u00e6sentlig begr\u00e6nsning p\u00e5 hvor meget arbejde der kan udf\u00f8res parallelt.","title":"Kontrol afh\u00e6ngigheder"},{"location":"afviklingsplot/kontrol/#kontrol-afhngigheder","text":"","title":"Kontrol afh\u00e6ngigheder"},{"location":"afviklingsplot/kontrol/#modellering","text":"Vi modellerer effekten af hop, kald og retur ved at forsinke F . For kald og retur skelner vi mellem korrekte og fejlagtige forudsigelser. For betingede hop skelner vi tillige mellem om hoppet tages eller ej. Vi udtrykker effekten ved tildelinger til en ny tidsvariabel: NextF.time Og for enhver instruktion g\u00e6lder altid at F.time >= NextF.time Vi tilf\u00f8jer en ny fase, B , specifik for betingede hop, kald og retur. B svarer til X for de aritmetiske instruktioner. B angiver det tidspunkt, hvor vi afg\u00f8r om forudsigelser af instruktionen var korrekt eller ej. Vi tillader at B indtr\u00e6ffer out-of-order i forhold til andre typer instruktioner, men kr\u00e6ver det sker in-order i forhold til andre hop, kald eller retur. call a,b: F----QBC ret a: F----QBC cbcc a,b,x: F----QBC inorder(B) Her er nogle mulige regler for en out-of-order maskine som beskrevet ovenfor Instruktion Taget Forudsagt Effekt Call ja ja produce(F+2,pc) Ret ja ja produce(F+2,pc) ja nej produce(B+1,pc) CBcc nej ja - (ikke muligt) nej nej produce(B+1,pc) ja ja produce(F+2,pc) ja nej produce(F+2,pc) Husk at pc er vores specielle register til at pege p\u00e5 n\u00e6ste instruktion, s\u00e5 ovenst\u00e5ende peger p\u00e5 hvor hurtigt n\u00e6ste instruktion kan v\u00e6re klar. Herunder ses to genneml\u00f8b af en indre l\u00f8kke, hvor hop forudsiges korrekt. 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C -- produce(F+2, pc) (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C Ydeevne: 5/4 IPC. L\u00e6g m\u00e6rke til at hoppet i denne eksekvering bliver taget korrekt og n\u00e6ste instruktion bliver derfor kun forsinket 2 clock perioder. P\u00e5 grund af omkostningen ved hop vil en overs\u00e6tter ofte rulle en l\u00f8kke-krop ud en eller flere gange. Herunder ses effekten af en enkelt udrulning 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbgt r10,r12,exit F----QB----C -- forudsagt korrekt ikke taget movq (r10),r11 F----QAM---C -- depend(A,r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C -- produce(F+2, pc) (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) Ydeevne: 10/6 IPC En anden teknik til at skjule omkostningen ved tagne hop er at man dimensionerer forenden af mikroarkitektur ( F til Q ) lidt st\u00f8rre end resten. Her er for eksempel et afviklingsplot for den ikke udrullede l\u00f8kke p\u00e5 en maskine der kan h\u00e5ndtere 3 instruktioner samtidigt i F til Q : 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----Q-AM--VC -- depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----Q-B----C -- produce(F+2, pc) (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C -- depends(A, r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----Q-AM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----Q-B----C Ydeevne: 5/3 IPC Her ses effekten af en forkert forudsigelse: 012345678901234567 loop: movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) cbl r10,r12,loop F----QB----C -- produce(B+1, pc) loop: movq (r10),r11 F----QAM--C -- depends(A, r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(V,r11), produce(V,r11) addq $8,r10 F----QX----C -- produce(X,r10) Ydeevne 5/9 IPC Jo l\u00e6ngere pipeline, jo st\u00f8rre omkostning ved forkerte forudsigelser.","title":"Modellering"},{"location":"afviklingsplot/kontrol/#spekulativ-udfrelse","text":"Det kan ske at B fasen indtr\u00e6ffer meget sent i forhold til udf\u00f8relsen af andre instruktioner. Betragt for eksempel nedenst\u00e5ende stump kode long v = tab[j]; if (v > key) { *ptr = *ptr + 1; // found it! } Oversat til x86prime kan det blive til f\u00f8lgende programstump: movq (r10,r11,8),r12 cble r12,r13,.endif movq (r15),r14 addq $1,r14 movq r14,(r15) .endif: og lad os antage at variablen tab befinder sig i L2-cache, mens omr\u00e5det udpeget af variablen ptr er i L1-cache. Lad os antage at L2-cache tilgang koster 10 cykler (oveni L1-tilgang). 01234567890123456789012 movq (r10,r11,8),r12 F----QAM------------C cble r12,r13,else F----Q--------------BC movq (r15),r14 F----QAM------------C addq $1,r14 F----Q----X----------C movq r14,(r15) F----QAM--V---------C Det betingede hop afh\u00e6nger af en instruktion der er n\u00f8d til at hente en v\u00e6rdi i L2 og bliver s\u00e5ledes forsinket s\u00e5 det f\u00f8rst kan afg\u00f8res i cyklus 20. Hoppet er forudsagt \"ikke taget\" og f\u00f8r det afg\u00f8res kan de n\u00e6ste tre instruktioner l\u00e6se fra L1-cachen, beregne en ny v\u00e6rdi og l\u00e6gge den i k\u00f8 til skrivning til L1. Det g\u00e5r selvsagt ikke an faktisk at opdatere L1, f\u00f8r vi ved om hoppet er forudsagt korrekt, men alle \u00f8vrige aktiviteter kan gennemf\u00f8res. De instruktioner som udf\u00f8res tidligere end et eller flere hop, kald eller retur, som de egentlig afh\u00e6nger af, siges at v\u00e6re spekulativt udf\u00f8rt. Spekulativ udf\u00f8relse fjerner en v\u00e6sentlig begr\u00e6nsning p\u00e5 hvor meget arbejde der kan udf\u00f8res parallelt.","title":"spekulativ udf\u00f8relse"},{"location":"afviklingsplot/out-of-order/","text":"Out-of-order eksekvering Id\u00e9en om out-of-order eksekvering (ogs\u00e5 kaldet dynamic scheduling) af kode er s\u00e5 gammel som processoren selv. Det er dog ret sv\u00e6rt at implementerer, s\u00e5 I mange \u00e5r fandtes det kun som en mulig program optimering, som n\u00e6vnt tidligere. Vi skal derfor helt frem til starten af 90'erne f\u00f8r det var en g\u00e6ngs del at mikroprocessorer. Faser i program-r\u00e6kkef\u00f8lge - eller ej Overvej afviklingen i f\u00f8lgende simple superskalar pipeline, hvor Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F--XW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F--XM-W depend(X,a), produce(M+1,b) Skrivning movq b,(a) F--XM depend(X,a), depend(M,b) Tilg\u00e6ngelige ressourcer: F:2 , X:2 , M:1 , W:2 Antal instruktioner under beregning: F-X: 4 , M-W: 1 01234567 -- Bem\u00e6rkning movq (r10),r11 F--XM-W -- produce(M+1,r11) addq $100,r11 F-----XW -- depend(X,r11), stall F til r11 er klar movq r9,(r14) F--XM -- ingen afh\u00e6ngighed, s\u00e5 hvorfor vente? <---- BEM\u00c6RK! addq $1,r10 F--XW -- ingen afh\u00e6ngighed Bem\u00e6rk at instruktion nummer 3 og 4 her f\u00e5r sin X -fase en clock periode tidligere end instruktionen f\u00f8r. P\u00e5 en m\u00e5de overhaler instruktion nummer 3 og 4 alts\u00e5 instruktion nummer 2. Det er ikke noget som bryder med antallet af tilg\u00e6ngelige ressourcer i vores superskalar maskine. Vi kan t\u00e6lle faserne i s\u00f8jlerne og alt er korrekt. Dog husker vi nu reglen for inorder(F,D,X,M,W) , som vi glemt at tage med. For at tjekke den skal vi sikre at faserne i hver s\u00f8jle er ordnet modsat oppefra og ned. Dette er oplagt ikke tilf\u00e6ldet i clock periode 4 og 5 hvor vi jo ser det to instruktioner har overhalet. S\u00e5 for er sikre inorder(F,D,X,M,W) er vi n\u00f8dt til at have: 012345678 -- Bem\u00e6rkning movq (r10),r11 F--XM-W -- produce(W,r11) addq $100,r11 F-----XW -- depend(X,r11), stall F til r11 er klar movq r9,(r14) F----XM -- ingen afh\u00e6ngighed, men stall i F for inorder addq $1,r10 F-----XW -- ingen afh\u00e6ngighed, men stall i F Vi kan for dette eksempel kun spare en enkelt clock periode, men vi kan ane at der findes meget mere ydeevne i form af mere parallelisme i udf\u00f8relsen, hvis vi blot kan afvige fra inorder-kravet i en eller flere faser. Det har man gjort for \"special cases\" i mange maskiner gennem \u00e5rene, men de sidste 20 \u00e5r er der etableret en mere generel \"standard model\" for out-of-order maskiner Standardmodellen for out-of-order mikroarkitektur Inorder og out-of-order I denne model passerer instruktioner f\u00f8rst i programr\u00e6kkef\u00f8lge gennem en indhentnings-pipeline til de ender i en skeduleringsenhed (scheduler). Derfra kan de udf\u00f8res uden at overholde programr\u00e6kkef\u00f8lgen. Efter udf\u00f8rsel placeres resultaterne i en form for k\u00f8. Resultaterne udtages fra denne k\u00f8 og fuldf\u00f8res igen i programr\u00e6kkef\u00f8lge. Det g\u00e6lder s\u00e5vel for skrivninger til registre, som for skrivninger til lageret. Vi kan beskrive det ved f\u00f8lgende faser der er f\u00e6lles for alle instruktioner: F : Start p\u00e5 instruktionsindhentning Q : Ankomst til scheduler C : Fuldf\u00f8relse Og vi benytter lejligheden til at fjerne W trinnet fra beskrivelsen. Lagerreferencer I de hidtil beskrevne maskiner bruger b\u00e5de lagerreferencer og aritmetiske instruktioner fasen X . Det afspejler at man i simple maskiner foretager adresseberegning med den samme hardware som man bruger til aritmetiske instruktioner. I standardmodellen har man i stedet en dedikeret fase til adresseberegning, kaldet A . Denne skelnen mellem A og X g\u00f8r at man kan begr\u00e6nse A til at forekomme i instruktionsr\u00e6kkef\u00f8lge, mens de andre beregninger ikke har den begr\u00e6nsning. Instruktioner der skriver til lageret har et v\u00e6sentlig mere kompliceret forl\u00f8b i en out-of-order maskine sammenlignet med en inorder maskine. Disse instruktioner m\u00e5 ikke opdatere lageret f\u00f8r C , s\u00e5 i stedet placeres skrivningerne i en skrive-k\u00f8. Skrive-k\u00f8en indeholder adresse og data som kan bruges til at udf\u00f8re skrivningen senere, efter C . Instruktioner indf\u00f8jes i skrivek\u00f8en umiddelbart efter A . Da A er en fase der udf\u00f8res i instruktionsr\u00e6kkef\u00f8lge, kan efterf\u00f8lgende instruktioner der l\u00e6ser fra lageret sammenligne deres adresse med udest\u00e5ende skrivninger i skrive-k\u00f8en, og hvis adressen matcher kan den tilsvarende v\u00e6rdi hentes fra skrive-k\u00f8en. Instruktioner der skriver til lageret kan (skal) inds\u00e6tte deres adresse i skrive-k\u00f8en selvom den v\u00e6rdi der skal skrives endnu ikke er beregnet. Det tidspunkt hvor v\u00e6rdien kopieres til skrive-k\u00f8en markeres V . En lille out-of-order model Her er en model af en lille out-of-order maskine: Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F----QXC depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F----QAM--C depend(A,a), produce(M+2,b) Skrivning movq b,(a) F----QAMVC depend(A,a), depend(V,b), produce(V,a) Tilg\u00e6ngelige ressourcer: F:2 , Q:2 , X:2 , A:1 , M:1 , V:1 , C:2 Antal instruktioner under beregning: F-Q: 8 , M-W: 2 , Q-C: 32 inorder(F,Q,C,A) outoforder(X,M) Bem\u00e6rk at udover at faserne X og M nu er erkl\u00e6ret out-of-order, s\u00e5 er der indsat en begr\u00e6nsning p\u00e5 32 instruktioner fra Q til C . Det vil sige vi tillader 32 instruktioner at v\u00e6re i forskellige faser mellem Q og C . Dette kaldes skeduleringsvinduet. Jo st\u00f8rre det er, jo flere instruktioner kan maskinen \"se fremad\" i instruktionsstr\u00f8mmen. Bem\u00e6rk ogs\u00e5 at til forskel fra alle de tidligere maskiner er der ikke l\u00e6ngere noget krav om X skal f\u00f8lge i en bestemt afstand efter Q , eller at C skal f\u00f8lge i en bestemt afstand efter X eller M . Disse begr\u00e6nsninger ville give f\u00f8lgende udf\u00f8relse 012345678901234 -- Vigtigste bem\u00e6rkninger movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(M,r11) addq $8,r10 F----QX----C -- produce(X,r10) movq (r10),r11 F----QAM---C -- depend(A,r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(M,r11) addq $8,r10 F----QX----C -- depend(X,r10), produce(X,r10) Med en gennemsnitlig ydeevne p\u00e5 2 IPC.","title":"Out-of-order"},{"location":"afviklingsplot/out-of-order/#out-of-order-eksekvering","text":"Id\u00e9en om out-of-order eksekvering (ogs\u00e5 kaldet dynamic scheduling) af kode er s\u00e5 gammel som processoren selv. Det er dog ret sv\u00e6rt at implementerer, s\u00e5 I mange \u00e5r fandtes det kun som en mulig program optimering, som n\u00e6vnt tidligere. Vi skal derfor helt frem til starten af 90'erne f\u00f8r det var en g\u00e6ngs del at mikroprocessorer.","title":"Out-of-order eksekvering"},{"location":"afviklingsplot/out-of-order/#faser-i-program-rkkeflge-eller-ej","text":"Overvej afviklingen i f\u00f8lgende simple superskalar pipeline, hvor Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F--XW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F--XM-W depend(X,a), produce(M+1,b) Skrivning movq b,(a) F--XM depend(X,a), depend(M,b) Tilg\u00e6ngelige ressourcer: F:2 , X:2 , M:1 , W:2 Antal instruktioner under beregning: F-X: 4 , M-W: 1 01234567 -- Bem\u00e6rkning movq (r10),r11 F--XM-W -- produce(M+1,r11) addq $100,r11 F-----XW -- depend(X,r11), stall F til r11 er klar movq r9,(r14) F--XM -- ingen afh\u00e6ngighed, s\u00e5 hvorfor vente? <---- BEM\u00c6RK! addq $1,r10 F--XW -- ingen afh\u00e6ngighed Bem\u00e6rk at instruktion nummer 3 og 4 her f\u00e5r sin X -fase en clock periode tidligere end instruktionen f\u00f8r. P\u00e5 en m\u00e5de overhaler instruktion nummer 3 og 4 alts\u00e5 instruktion nummer 2. Det er ikke noget som bryder med antallet af tilg\u00e6ngelige ressourcer i vores superskalar maskine. Vi kan t\u00e6lle faserne i s\u00f8jlerne og alt er korrekt. Dog husker vi nu reglen for inorder(F,D,X,M,W) , som vi glemt at tage med. For at tjekke den skal vi sikre at faserne i hver s\u00f8jle er ordnet modsat oppefra og ned. Dette er oplagt ikke tilf\u00e6ldet i clock periode 4 og 5 hvor vi jo ser det to instruktioner har overhalet. S\u00e5 for er sikre inorder(F,D,X,M,W) er vi n\u00f8dt til at have: 012345678 -- Bem\u00e6rkning movq (r10),r11 F--XM-W -- produce(W,r11) addq $100,r11 F-----XW -- depend(X,r11), stall F til r11 er klar movq r9,(r14) F----XM -- ingen afh\u00e6ngighed, men stall i F for inorder addq $1,r10 F-----XW -- ingen afh\u00e6ngighed, men stall i F Vi kan for dette eksempel kun spare en enkelt clock periode, men vi kan ane at der findes meget mere ydeevne i form af mere parallelisme i udf\u00f8relsen, hvis vi blot kan afvige fra inorder-kravet i en eller flere faser. Det har man gjort for \"special cases\" i mange maskiner gennem \u00e5rene, men de sidste 20 \u00e5r er der etableret en mere generel \"standard model\" for out-of-order maskiner","title":"Faser i program-r\u00e6kkef\u00f8lge - eller ej"},{"location":"afviklingsplot/out-of-order/#standardmodellen-for-out-of-order-mikroarkitektur","text":"","title":"Standardmodellen for out-of-order mikroarkitektur"},{"location":"afviklingsplot/out-of-order/#inorder-og-out-of-order","text":"I denne model passerer instruktioner f\u00f8rst i programr\u00e6kkef\u00f8lge gennem en indhentnings-pipeline til de ender i en skeduleringsenhed (scheduler). Derfra kan de udf\u00f8res uden at overholde programr\u00e6kkef\u00f8lgen. Efter udf\u00f8rsel placeres resultaterne i en form for k\u00f8. Resultaterne udtages fra denne k\u00f8 og fuldf\u00f8res igen i programr\u00e6kkef\u00f8lge. Det g\u00e6lder s\u00e5vel for skrivninger til registre, som for skrivninger til lageret. Vi kan beskrive det ved f\u00f8lgende faser der er f\u00e6lles for alle instruktioner: F : Start p\u00e5 instruktionsindhentning Q : Ankomst til scheduler C : Fuldf\u00f8relse Og vi benytter lejligheden til at fjerne W trinnet fra beskrivelsen.","title":"Inorder og out-of-order"},{"location":"afviklingsplot/out-of-order/#lagerreferencer","text":"I de hidtil beskrevne maskiner bruger b\u00e5de lagerreferencer og aritmetiske instruktioner fasen X . Det afspejler at man i simple maskiner foretager adresseberegning med den samme hardware som man bruger til aritmetiske instruktioner. I standardmodellen har man i stedet en dedikeret fase til adresseberegning, kaldet A . Denne skelnen mellem A og X g\u00f8r at man kan begr\u00e6nse A til at forekomme i instruktionsr\u00e6kkef\u00f8lge, mens de andre beregninger ikke har den begr\u00e6nsning. Instruktioner der skriver til lageret har et v\u00e6sentlig mere kompliceret forl\u00f8b i en out-of-order maskine sammenlignet med en inorder maskine. Disse instruktioner m\u00e5 ikke opdatere lageret f\u00f8r C , s\u00e5 i stedet placeres skrivningerne i en skrive-k\u00f8. Skrive-k\u00f8en indeholder adresse og data som kan bruges til at udf\u00f8re skrivningen senere, efter C . Instruktioner indf\u00f8jes i skrivek\u00f8en umiddelbart efter A . Da A er en fase der udf\u00f8res i instruktionsr\u00e6kkef\u00f8lge, kan efterf\u00f8lgende instruktioner der l\u00e6ser fra lageret sammenligne deres adresse med udest\u00e5ende skrivninger i skrive-k\u00f8en, og hvis adressen matcher kan den tilsvarende v\u00e6rdi hentes fra skrive-k\u00f8en. Instruktioner der skriver til lageret kan (skal) inds\u00e6tte deres adresse i skrive-k\u00f8en selvom den v\u00e6rdi der skal skrives endnu ikke er beregnet. Det tidspunkt hvor v\u00e6rdien kopieres til skrive-k\u00f8en markeres V .","title":"Lagerreferencer"},{"location":"afviklingsplot/out-of-order/#en-lille-out-of-order-model","text":"Her er en model af en lille out-of-order maskine: Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b F----QXC depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b F----QAM--C depend(A,a), produce(M+2,b) Skrivning movq b,(a) F----QAMVC depend(A,a), depend(V,b), produce(V,a) Tilg\u00e6ngelige ressourcer: F:2 , Q:2 , X:2 , A:1 , M:1 , V:1 , C:2 Antal instruktioner under beregning: F-Q: 8 , M-W: 2 , Q-C: 32 inorder(F,Q,C,A) outoforder(X,M) Bem\u00e6rk at udover at faserne X og M nu er erkl\u00e6ret out-of-order, s\u00e5 er der indsat en begr\u00e6nsning p\u00e5 32 instruktioner fra Q til C . Det vil sige vi tillader 32 instruktioner at v\u00e6re i forskellige faser mellem Q og C . Dette kaldes skeduleringsvinduet. Jo st\u00f8rre det er, jo flere instruktioner kan maskinen \"se fremad\" i instruktionsstr\u00f8mmen. Bem\u00e6rk ogs\u00e5 at til forskel fra alle de tidligere maskiner er der ikke l\u00e6ngere noget krav om X skal f\u00f8lge i en bestemt afstand efter Q , eller at C skal f\u00f8lge i en bestemt afstand efter X eller M . Disse begr\u00e6nsninger ville give f\u00f8lgende udf\u00f8relse 012345678901234 -- Vigtigste bem\u00e6rkninger movq (r10),r11 F----QAM--C -- produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(M,r11) addq $8,r10 F----QX----C -- produce(X,r10) movq (r10),r11 F----QAM---C -- depend(A,r10), produce(M+2,r11) addq $100,r11 F----Q----XC -- depend(X,r11), produce(X,r11) movq r11,(r10) F----QAM--VC -- depend(A,r10), depend(M,r11) addq $8,r10 F----QX----C -- depend(X,r10), produce(X,r10) Med en gennemsnitlig ydeevne p\u00e5 2 IPC.","title":"En lille out-of-order model"},{"location":"afviklingsplot/pipeline/","text":"Pipeline faser og ressourcer Siden slutningen af 70'erne hvor de f\u00f8rste pipeline arkitekturer blev introduceret, har en instruktion gennemg\u00e5et flere faser n\u00e5r den afvikles. Nogle faser er generiske; nogle afh\u00e6nger af instruktionen. Faserne genneml\u00f8bes i r\u00e6kkef\u00f8lge bestemt af instruktionstype og mikroarkitektur. Betragt for eksempel afviklingen p\u00e5 en simpel pipeline, typisk for de f\u00f8rste RISC maskiner konstrueret i 80'erne. Her er der fem faser: F : Fetch, indl\u00e6sning af instruktionen fra hukommelse, D : Decode, afkodning af instruktionen og udl\u00e6sning fra registerfil, X : eXecute, udf\u00f8rsel af aritmetisk/logisk operation, samt beregning af mulig adresse, M : Memory, l\u00e6sning fra eller skrivning til hukommelsen, W : Writeback, tilbageskrivning til registerfilen. Her ses nogle begr\u00e6nsninger for en 5-trins pipeline: Alle instruktioner genneml\u00f8ber: FDXMW Tilg\u00e6ngelige ressourcer: F:1 , D:1 , X:1 , M:1 , W:1 Ovenst\u00e5ende skal l\u00e6ses som: alle instruktioner passerer gennem samtlige fem trin ordnet som beskrevet; der findes en ressource for hvert trin, alts\u00e5 der kan kun v\u00e6re en instruktion i hver trin. Bem\u00e6rk at det er en voldsom forenkling at udtrykke begr\u00e6nsningen for instruktionshentning i et antal instruktioner. Is\u00e6r hvis instruktionen kommer til at ligge over to cache linier. For en maskine med instruktioner af forskellig l\u00e6ngde er bindingen mere korrekt udtrykt som et antal bytes. F\u00f8rst i forbindelse med afkodning er det klart, hvor en instruktion begynder og slutter. Den lille detalje vil vi se bort fra. Eksempel: Simpel pipeline mikroarkitektur For eksempel vil afviklingsplottet for et mindre udvidet eksempel program, vil v\u00e6re f\u00f8lgende: 012345678 movq (r10),r11 FDXMW mulq r10,r12 FDXMW addq $100,r13 FDXMW movq r14,(r10) FDXMW subq $1,r10 FDXMW Her ses at f\u00f8rste instruktion bliver indhentet i f\u00f8rste clock periode. I anden clock periode vil anden instruktion blive indhentet samtidig med at f\u00f8rste instruktion bliver afkodet, osv. Det er vigtigt at vi overholde begr\u00e6nsningerne. For at tjekke det ser vi at: * f\u00f8rste begr\u00e6nsning bliver overholdt, da alle linier i plottet indeholder alle fem trin, og * anden begr\u00e6nsning bliver overholdt da hver s\u00f8jle (clock periode) kun indeholder hvert trin en gang. Hvis vi pr\u00f8ver at udregne ydeevnen for programmet, kan vi se at det samlet bruger 9 clock perioder: dette svare til antallet af instruktioner (5) + antallet af trin minus 1. Vi kan derefter udregne CPI = 9/5 = 1,8 . Hvis vi sammenligner med vores enkelt-cyklus maskine (som vi have en CPI = 1 , er dette n\u00e6sten dobbelt s\u00e5 mange clock perioder. Men en periode p\u00e5 den simple pipeline maskine vil ogs\u00e5 v\u00e6re signifikant kortere; det kan v\u00e6re sv\u00e6rt at sige pr\u00e6cist hvor meget, men et kvalificeret g\u00e6t vil v\u00e6re ca. 1/3. Dette vil give en relativ CPI for enkeltcyklus maskinen p\u00e5 3; alts\u00e5 enkeltcyklus maskinen kan udf\u00f8re en instruktion p\u00e5 3 clock perioder p\u00e5 vores pipeline maskine. Dette vil g\u00f8re at denne maskine kun tager 1,8/3 = 60 % af tiden for at udf\u00f8re programmet. Latenstid af faser P\u00e5 en pipeline arkitektur bruger instruktioner en eller flere clock-perioder til at producere et resultat. Det kaldes instruktionens latenstid. Latenstiden er den tid der g\u00e5r fra instruktionen modtager/fremfinder sin sidste indg\u00e5ende operand og til en efterf\u00f8lgende instruktion som afh\u00e6nger af resultatet kan begynde sin beregning. Man planl\u00e6gger normalt en mikroarkitektur s\u00e5ledes at de grundl\u00e6ggende aritmetisk og logiske instruktioner har en latenstid p\u00e5 en enkelt clock periode. Andre instruktioner kan s\u00e5 f\u00e5 l\u00e6ngere latenstid, fordi de udf\u00f8rer et mere kompliceret stykke arbejde. For eksempel er multiplikation mere kompliceret end addition og har derfor en latenstid p\u00e5 3-4 clock perioder. Tilgang til lageret er ogs\u00e5 mere kompliceret og tager l\u00e6ngere tid end en enkelt clock periode. Eksempel: Latenstid Lad os unders\u00f8ge en pipelinet maskine og definere latenstiden i clock perioder (delay) for instruktionerne som: Simpel aritmetik op a b : delay(X)=1 Multiplikation mul a b : delay(X)=4 L\u00e6sning movq (a),b : delay(M)=2 Skrivning movq b,(a) : delay(M)=2 Alle \u00f8vrige faser taget har en latenstid p\u00e5 1 Husk vi har stadig: Alle instruktioner genneml\u00f8ber: FDXMW Tilg\u00e6ngelige ressourcer: F:1 , D:1 , X:1 , M:1 , W:1 Det tidligere eksempel, vil nu blive 111 0123456789012 movq (r10),r11 FDXMMW mulq r10,r12 FDXXXXMW addq $100,r13 FDDDDXMW movq r14,(r10) FFFFDXMMW subq $1,r10 FDXXMW Da vi i f\u00f8rste instruktion l\u00e6ser fra hukommelsen, vil M fasen nu tage to cykler. Det samme ses for anden instruktion, der nu bliver i X fasen i fire clock perioder. Tredje instruktion er tilgeng\u00e6ld mindre \u00e5benlys. Vi skal stadig overholde de to begr\u00e6nsninger fra tidligere. Specifikt kan addq instruktionen ikke begynde X fasen f\u00f8r mulq er f\u00e6rdig. Derfor laves en forsinkelse (\"stall\"), som sikre addq bliver i D fasen. P\u00e5 samme m\u00e5de er vi n\u00f8dt til at forsinke skrivningen i fjerde instruktion ved at stalle den i F . Indl\u00e6sningen af sidste instruktion, subq , kan derfor ikke begyndes f\u00f8r clock periode nummer 7, n\u00e5r F frigives fra den tidligere instruktion. L\u00e6g ogs\u00e5 m\u00e6rke til at instruktionen er n\u00f8dt til at stalle i X . Igen ser vi at: alle linier i plottet indeholder alle fem trin mindst en gang, og hver s\u00f8jle (clock periode) kun indeholder hvert trin en gang. Vi kan igen pr\u00f8ver at udregne ydeevnen for programmet og se at det samlet bruger 13 clock perioder for de 5 instruktioner; alts\u00e5 en CPI = 13/5 = 2,6 . Igen bliver det flere perioder hvis vi sammenligner med den simple pipeline, men igen kan vi forvente en kortere clock periode; nok mindst dobbelt s\u00e5 hurtig. Data afh\u00e6ngigheder og forwarding Mere signifikant end latenstiden er data afh\u00e6ngigheder. Det har ikke v\u00e6ret et problem i vores tidligere eksempler (ikke en tilf\u00e6ldighed), men kan hurtigt blive det for normale programmer. Overvej f\u00f8lgende program: movq (r10),r11 addq $100,r11 movq r11,(r10) addq $8,r10 subq $1,r12 Her bliver register r11 opdateret i instruktionen lige f\u00f8r det bliver l\u00e6st; endda to gange. F.eks. indl\u00e6ser f\u00f8rste instruktion en v\u00e6rdi til r11 , som anden instruktion straks l\u00e6gger noget til; men ogs\u00e5 fra anden til tredje instruktion. Vi kan lave data-flow graph, som beskrevet i CSapp, som vil tydeligg\u00f8re de data afh\u00e6ngigheder, som eksisterer i programmet. Instruktionsnummeret er indsat efter navnet. r10 r11 r12 | \\ | | | movq1 | | | | | addq2 | | / | | movq3 | | | | | addq4 | subq5 | | | r10 r11 r12 Hvis vi laver et simpelt afviklingsplot som f\u00f8r, vil vi f\u00e5 f\u00f8lgende: movq (r10),r11 FDXMMW addq $100,r11 FDXXMW movq r11,(r10) FDDXMMW addq $8,r10 FDDXXMW subq $1,r12 FFDDXMW (OVENST\u00c5ENDE VIRKER IKKE) Ud over den tydelige tekst, som indikerer det, kan vi overbevise os selv om at ovenst\u00e5ende ikke virker. Vi har en data afh\u00e6ngighed mellem l\u00e6sningen og f\u00f8rst addition og vi ved fra den tidligere uformelle beskrivelse at l\u00e6sning fra hukommelse sker i M fasen. Men i plottet laver vi additionen i X samtidig med M ; alts\u00e5 f\u00f8r vi har v\u00e6rdien til r\u00e5dighed. For at undg\u00e5 dette er vi n\u00f8dt til at tilf\u00f8je afh\u00e6ngighederne til vores instruktioner. Det kan vi skrive p\u00e5 f\u00f8lgende m\u00e5de: Aritmetik op a b : depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b : depend(X,a), produce(M,b) Skrivning movq b,(a) : depend(X,a), depend(M,b) Her st\u00e5r at aritmetiske instruktioner er afh\u00e6ngige af, at v\u00e6rdierne for b\u00e5de a og b er klar til fase X , samt at de producerer deres resultat til register b i fase X , som s\u00e5 kan bruges fra starten af fase M . L\u00e6sning fra hukommelsen kr\u00e6ver at adressen der skal l\u00e6ses fra register a er klar til fase X (husk at vi har beregningen af adressen i X fasen, selvom l\u00e6sningen f\u00f8rst foreg\u00e5r i M fasen), mens resultatet af l\u00e6sningen til register b er klar i fase M alts\u00e5 til fase W . Ved skrivning til hukommelsen skal adressen i register a v\u00e6re klar til fase X , mens v\u00e6rdien f\u00f8rst skal v\u00e6re klar til fase M . Skrivning til hukommelsen har ikke noget resultat. Det er vigtigt at vi her ogs\u00e5 medtager vores delay. V\u00e6r opm\u00e6rksom p\u00e5 at ovenst\u00e5ende implementerer en arkitektur med fuld forwarding. Alts\u00e5 at alle v\u00e6rdier kan bruges umiddelbart i n\u00e6ste clock periode i alle efterf\u00f8lgende instruktioner; dvs. f\u00f8r de reelt set er skrevet tilbage til registerfilen. Hvis vi i stedet ville have en maskine uden forwarding, ville alle v\u00e6rdier bliver produceret til fase W , hvor vi reelt skriver v\u00e6rdien tilbage. Eksempel: Data afh\u00e6ngigheder Lad os nu definere det korrekte afviklingspot for eksemplet. F\u00f8rst, lad os dog opsummere alt vi har defineret for maskinen: Tilg\u00e6ngelige ressourcer: F:1 , D:1 , X:1 , M:1 , W:1 Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b FDXMW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b FDXMW depend(X,a), produce(M,b) Skrivning movq b,(a) FDXMW depend(X,a), depend(M,b) Simpel aritmetik op a b : delay(X)=1 L\u00e6sning movq (a),b : delay(M)=2 Skrivning movq b,(a) : delay(M)=2 Alle \u00f8vrige faser taget har en latenstid p\u00e5 1 012345678901 -- Beskrivelse movq (r10),r11 FDXMMW -- produce(M,r11) addq $100,r11 FDDDXMW -- depend(X,r11), produce(X,r11), stall i D movq r11,(r10) FFFDXMMW -- Stall i F, depend(X,r11) addq $8,r10 FDXXMW -- Forsinket F subq $1,r12 FDDXMW -- Bem\u00e6rk hvorledes instruktion nr. 2 bliver forsinket en clock periode i sin D -fase, fordi den afh\u00e6nger af r11 som bliver produceret af den forudg\u00e5ende instruktion der har en latenstid p\u00e5 2 clock-perioder. Dette vil give en CPI = 12/5 = 2,4 . In-order udf\u00f8rsel af instruktioner Men hov! Vi har lige fundet ud af at sidste instruktion ikke har dataafh\u00e6ngigheder til de \u00f8vrige, s\u00e5 hvorfor kan vi ikke spare en clock periode ved at lave: 012345678901 -- Beskrivelse movq (r10),r11 FDXMMW -- produce(M,r11) addq $100,r11 FDDXMW -- depend(X,r11), produce(X,r11), stall i D movq r11,(r10) FFFDXMMW -- Stall i F, depend(X,r11) addq $8,r10 FDXXMW -- Forsinket F subq $1,r12 FDXXMW -- Vi har m\u00e5ske lidt sv\u00e6rt ved at se, hvordan en maskine overhovedet skulle kunne konstrueres s\u00e5ledes at ovenst\u00e5ende afviklingsr\u00e6kkef\u00f8lge kunne finde sted og en maskine er n\u00f8dt til at l\u00e6se instruktionerne i den r\u00e6kkef\u00f8lge, som er specificeret i vores program. Vi indf\u00f8rer derfor en begr\u00e6nsning mere: Hver fase gennemf\u00f8res i instruktions-r\u00e6kkef\u00f8lge. inorder(F,D,X,M,W) Vi har overholdt dette i tidligere eksempler. Vi kan tjekke det ved at n\u00e5r vi l\u00e6ser hver s\u00f8jle oppefra, skal vi se faserne bagfra. I det her tilf\u00e6lde kan vores overs\u00e6tter forbedre situationen, ved at flytte sidste instruktion frem. Dermed kan vi opn\u00e5 ovenst\u00e5ende udf\u00f8rsel: 01234567890 -- Beskrivelse movq (r10),r11 FDXMMW -- produce(M,r11) subq $1,r12 FDXXMW -- addq $100,r11 FDDXMW -- depend(X,r11), produce(X,r11), stall i D movq r11,(r10) FFDXMMW -- Stall i F, depend(X,r11) addq $8,r10 FDXXMW -- Forsinket F Vi kan alts\u00e5 n\u00f8jes med at benytte 11 clock perioder og f\u00e5r dermed en CPI = 11/5 = 2,2 . Kontrolafh\u00e6ngigheder Den opm\u00e6rksomme l\u00e6ser har nok lagt m\u00e6rke til at alle tidligere programmer og mikroarkitekturer har manglet noget. Vi har endnu kun snakket om sekventielle instruktioner og ikke overvejet kontrolinstruktioner. Det skyldes at det g\u00f8r vores plots og model signifikant mere kompliceret og senere udvidelser vil faktisk g\u00f8re det nemmere. Det er derfor noget som I stadig m\u00e5 gl\u00e6de jer til.","title":"Simpel pipeline"},{"location":"afviklingsplot/pipeline/#pipeline-faser-og-ressourcer","text":"Siden slutningen af 70'erne hvor de f\u00f8rste pipeline arkitekturer blev introduceret, har en instruktion gennemg\u00e5et flere faser n\u00e5r den afvikles. Nogle faser er generiske; nogle afh\u00e6nger af instruktionen. Faserne genneml\u00f8bes i r\u00e6kkef\u00f8lge bestemt af instruktionstype og mikroarkitektur. Betragt for eksempel afviklingen p\u00e5 en simpel pipeline, typisk for de f\u00f8rste RISC maskiner konstrueret i 80'erne. Her er der fem faser: F : Fetch, indl\u00e6sning af instruktionen fra hukommelse, D : Decode, afkodning af instruktionen og udl\u00e6sning fra registerfil, X : eXecute, udf\u00f8rsel af aritmetisk/logisk operation, samt beregning af mulig adresse, M : Memory, l\u00e6sning fra eller skrivning til hukommelsen, W : Writeback, tilbageskrivning til registerfilen. Her ses nogle begr\u00e6nsninger for en 5-trins pipeline: Alle instruktioner genneml\u00f8ber: FDXMW Tilg\u00e6ngelige ressourcer: F:1 , D:1 , X:1 , M:1 , W:1 Ovenst\u00e5ende skal l\u00e6ses som: alle instruktioner passerer gennem samtlige fem trin ordnet som beskrevet; der findes en ressource for hvert trin, alts\u00e5 der kan kun v\u00e6re en instruktion i hver trin. Bem\u00e6rk at det er en voldsom forenkling at udtrykke begr\u00e6nsningen for instruktionshentning i et antal instruktioner. Is\u00e6r hvis instruktionen kommer til at ligge over to cache linier. For en maskine med instruktioner af forskellig l\u00e6ngde er bindingen mere korrekt udtrykt som et antal bytes. F\u00f8rst i forbindelse med afkodning er det klart, hvor en instruktion begynder og slutter. Den lille detalje vil vi se bort fra.","title":"Pipeline faser og ressourcer"},{"location":"afviklingsplot/pipeline/#eksempel-simpel-pipeline-mikroarkitektur","text":"For eksempel vil afviklingsplottet for et mindre udvidet eksempel program, vil v\u00e6re f\u00f8lgende: 012345678 movq (r10),r11 FDXMW mulq r10,r12 FDXMW addq $100,r13 FDXMW movq r14,(r10) FDXMW subq $1,r10 FDXMW Her ses at f\u00f8rste instruktion bliver indhentet i f\u00f8rste clock periode. I anden clock periode vil anden instruktion blive indhentet samtidig med at f\u00f8rste instruktion bliver afkodet, osv. Det er vigtigt at vi overholde begr\u00e6nsningerne. For at tjekke det ser vi at: * f\u00f8rste begr\u00e6nsning bliver overholdt, da alle linier i plottet indeholder alle fem trin, og * anden begr\u00e6nsning bliver overholdt da hver s\u00f8jle (clock periode) kun indeholder hvert trin en gang. Hvis vi pr\u00f8ver at udregne ydeevnen for programmet, kan vi se at det samlet bruger 9 clock perioder: dette svare til antallet af instruktioner (5) + antallet af trin minus 1. Vi kan derefter udregne CPI = 9/5 = 1,8 . Hvis vi sammenligner med vores enkelt-cyklus maskine (som vi have en CPI = 1 , er dette n\u00e6sten dobbelt s\u00e5 mange clock perioder. Men en periode p\u00e5 den simple pipeline maskine vil ogs\u00e5 v\u00e6re signifikant kortere; det kan v\u00e6re sv\u00e6rt at sige pr\u00e6cist hvor meget, men et kvalificeret g\u00e6t vil v\u00e6re ca. 1/3. Dette vil give en relativ CPI for enkeltcyklus maskinen p\u00e5 3; alts\u00e5 enkeltcyklus maskinen kan udf\u00f8re en instruktion p\u00e5 3 clock perioder p\u00e5 vores pipeline maskine. Dette vil g\u00f8re at denne maskine kun tager 1,8/3 = 60 % af tiden for at udf\u00f8re programmet.","title":"Eksempel: Simpel pipeline mikroarkitektur"},{"location":"afviklingsplot/pipeline/#latenstid-af-faser","text":"P\u00e5 en pipeline arkitektur bruger instruktioner en eller flere clock-perioder til at producere et resultat. Det kaldes instruktionens latenstid. Latenstiden er den tid der g\u00e5r fra instruktionen modtager/fremfinder sin sidste indg\u00e5ende operand og til en efterf\u00f8lgende instruktion som afh\u00e6nger af resultatet kan begynde sin beregning. Man planl\u00e6gger normalt en mikroarkitektur s\u00e5ledes at de grundl\u00e6ggende aritmetisk og logiske instruktioner har en latenstid p\u00e5 en enkelt clock periode. Andre instruktioner kan s\u00e5 f\u00e5 l\u00e6ngere latenstid, fordi de udf\u00f8rer et mere kompliceret stykke arbejde. For eksempel er multiplikation mere kompliceret end addition og har derfor en latenstid p\u00e5 3-4 clock perioder. Tilgang til lageret er ogs\u00e5 mere kompliceret og tager l\u00e6ngere tid end en enkelt clock periode.","title":"Latenstid af faser"},{"location":"afviklingsplot/pipeline/#eksempel-latenstid","text":"Lad os unders\u00f8ge en pipelinet maskine og definere latenstiden i clock perioder (delay) for instruktionerne som: Simpel aritmetik op a b : delay(X)=1 Multiplikation mul a b : delay(X)=4 L\u00e6sning movq (a),b : delay(M)=2 Skrivning movq b,(a) : delay(M)=2 Alle \u00f8vrige faser taget har en latenstid p\u00e5 1 Husk vi har stadig: Alle instruktioner genneml\u00f8ber: FDXMW Tilg\u00e6ngelige ressourcer: F:1 , D:1 , X:1 , M:1 , W:1 Det tidligere eksempel, vil nu blive 111 0123456789012 movq (r10),r11 FDXMMW mulq r10,r12 FDXXXXMW addq $100,r13 FDDDDXMW movq r14,(r10) FFFFDXMMW subq $1,r10 FDXXMW Da vi i f\u00f8rste instruktion l\u00e6ser fra hukommelsen, vil M fasen nu tage to cykler. Det samme ses for anden instruktion, der nu bliver i X fasen i fire clock perioder. Tredje instruktion er tilgeng\u00e6ld mindre \u00e5benlys. Vi skal stadig overholde de to begr\u00e6nsninger fra tidligere. Specifikt kan addq instruktionen ikke begynde X fasen f\u00f8r mulq er f\u00e6rdig. Derfor laves en forsinkelse (\"stall\"), som sikre addq bliver i D fasen. P\u00e5 samme m\u00e5de er vi n\u00f8dt til at forsinke skrivningen i fjerde instruktion ved at stalle den i F . Indl\u00e6sningen af sidste instruktion, subq , kan derfor ikke begyndes f\u00f8r clock periode nummer 7, n\u00e5r F frigives fra den tidligere instruktion. L\u00e6g ogs\u00e5 m\u00e6rke til at instruktionen er n\u00f8dt til at stalle i X . Igen ser vi at: alle linier i plottet indeholder alle fem trin mindst en gang, og hver s\u00f8jle (clock periode) kun indeholder hvert trin en gang. Vi kan igen pr\u00f8ver at udregne ydeevnen for programmet og se at det samlet bruger 13 clock perioder for de 5 instruktioner; alts\u00e5 en CPI = 13/5 = 2,6 . Igen bliver det flere perioder hvis vi sammenligner med den simple pipeline, men igen kan vi forvente en kortere clock periode; nok mindst dobbelt s\u00e5 hurtig.","title":"Eksempel: Latenstid"},{"location":"afviklingsplot/pipeline/#data-afhngigheder-og-forwarding","text":"Mere signifikant end latenstiden er data afh\u00e6ngigheder. Det har ikke v\u00e6ret et problem i vores tidligere eksempler (ikke en tilf\u00e6ldighed), men kan hurtigt blive det for normale programmer. Overvej f\u00f8lgende program: movq (r10),r11 addq $100,r11 movq r11,(r10) addq $8,r10 subq $1,r12 Her bliver register r11 opdateret i instruktionen lige f\u00f8r det bliver l\u00e6st; endda to gange. F.eks. indl\u00e6ser f\u00f8rste instruktion en v\u00e6rdi til r11 , som anden instruktion straks l\u00e6gger noget til; men ogs\u00e5 fra anden til tredje instruktion. Vi kan lave data-flow graph, som beskrevet i CSapp, som vil tydeligg\u00f8re de data afh\u00e6ngigheder, som eksisterer i programmet. Instruktionsnummeret er indsat efter navnet. r10 r11 r12 | \\ | | | movq1 | | | | | addq2 | | / | | movq3 | | | | | addq4 | subq5 | | | r10 r11 r12 Hvis vi laver et simpelt afviklingsplot som f\u00f8r, vil vi f\u00e5 f\u00f8lgende: movq (r10),r11 FDXMMW addq $100,r11 FDXXMW movq r11,(r10) FDDXMMW addq $8,r10 FDDXXMW subq $1,r12 FFDDXMW (OVENST\u00c5ENDE VIRKER IKKE) Ud over den tydelige tekst, som indikerer det, kan vi overbevise os selv om at ovenst\u00e5ende ikke virker. Vi har en data afh\u00e6ngighed mellem l\u00e6sningen og f\u00f8rst addition og vi ved fra den tidligere uformelle beskrivelse at l\u00e6sning fra hukommelse sker i M fasen. Men i plottet laver vi additionen i X samtidig med M ; alts\u00e5 f\u00f8r vi har v\u00e6rdien til r\u00e5dighed. For at undg\u00e5 dette er vi n\u00f8dt til at tilf\u00f8je afh\u00e6ngighederne til vores instruktioner. Det kan vi skrive p\u00e5 f\u00f8lgende m\u00e5de: Aritmetik op a b : depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b : depend(X,a), produce(M,b) Skrivning movq b,(a) : depend(X,a), depend(M,b) Her st\u00e5r at aritmetiske instruktioner er afh\u00e6ngige af, at v\u00e6rdierne for b\u00e5de a og b er klar til fase X , samt at de producerer deres resultat til register b i fase X , som s\u00e5 kan bruges fra starten af fase M . L\u00e6sning fra hukommelsen kr\u00e6ver at adressen der skal l\u00e6ses fra register a er klar til fase X (husk at vi har beregningen af adressen i X fasen, selvom l\u00e6sningen f\u00f8rst foreg\u00e5r i M fasen), mens resultatet af l\u00e6sningen til register b er klar i fase M alts\u00e5 til fase W . Ved skrivning til hukommelsen skal adressen i register a v\u00e6re klar til fase X , mens v\u00e6rdien f\u00f8rst skal v\u00e6re klar til fase M . Skrivning til hukommelsen har ikke noget resultat. Det er vigtigt at vi her ogs\u00e5 medtager vores delay. V\u00e6r opm\u00e6rksom p\u00e5 at ovenst\u00e5ende implementerer en arkitektur med fuld forwarding. Alts\u00e5 at alle v\u00e6rdier kan bruges umiddelbart i n\u00e6ste clock periode i alle efterf\u00f8lgende instruktioner; dvs. f\u00f8r de reelt set er skrevet tilbage til registerfilen. Hvis vi i stedet ville have en maskine uden forwarding, ville alle v\u00e6rdier bliver produceret til fase W , hvor vi reelt skriver v\u00e6rdien tilbage.","title":"Data afh\u00e6ngigheder og forwarding"},{"location":"afviklingsplot/pipeline/#eksempel-data-afhngigheder","text":"Lad os nu definere det korrekte afviklingspot for eksemplet. F\u00f8rst, lad os dog opsummere alt vi har defineret for maskinen: Tilg\u00e6ngelige ressourcer: F:1 , D:1 , X:1 , M:1 , W:1 Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b FDXMW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b FDXMW depend(X,a), produce(M,b) Skrivning movq b,(a) FDXMW depend(X,a), depend(M,b) Simpel aritmetik op a b : delay(X)=1 L\u00e6sning movq (a),b : delay(M)=2 Skrivning movq b,(a) : delay(M)=2 Alle \u00f8vrige faser taget har en latenstid p\u00e5 1 012345678901 -- Beskrivelse movq (r10),r11 FDXMMW -- produce(M,r11) addq $100,r11 FDDDXMW -- depend(X,r11), produce(X,r11), stall i D movq r11,(r10) FFFDXMMW -- Stall i F, depend(X,r11) addq $8,r10 FDXXMW -- Forsinket F subq $1,r12 FDDXMW -- Bem\u00e6rk hvorledes instruktion nr. 2 bliver forsinket en clock periode i sin D -fase, fordi den afh\u00e6nger af r11 som bliver produceret af den forudg\u00e5ende instruktion der har en latenstid p\u00e5 2 clock-perioder. Dette vil give en CPI = 12/5 = 2,4 .","title":"Eksempel: Data afh\u00e6ngigheder"},{"location":"afviklingsplot/pipeline/#in-order-udfrsel-af-instruktioner","text":"Men hov! Vi har lige fundet ud af at sidste instruktion ikke har dataafh\u00e6ngigheder til de \u00f8vrige, s\u00e5 hvorfor kan vi ikke spare en clock periode ved at lave: 012345678901 -- Beskrivelse movq (r10),r11 FDXMMW -- produce(M,r11) addq $100,r11 FDDXMW -- depend(X,r11), produce(X,r11), stall i D movq r11,(r10) FFFDXMMW -- Stall i F, depend(X,r11) addq $8,r10 FDXXMW -- Forsinket F subq $1,r12 FDXXMW -- Vi har m\u00e5ske lidt sv\u00e6rt ved at se, hvordan en maskine overhovedet skulle kunne konstrueres s\u00e5ledes at ovenst\u00e5ende afviklingsr\u00e6kkef\u00f8lge kunne finde sted og en maskine er n\u00f8dt til at l\u00e6se instruktionerne i den r\u00e6kkef\u00f8lge, som er specificeret i vores program. Vi indf\u00f8rer derfor en begr\u00e6nsning mere: Hver fase gennemf\u00f8res i instruktions-r\u00e6kkef\u00f8lge. inorder(F,D,X,M,W) Vi har overholdt dette i tidligere eksempler. Vi kan tjekke det ved at n\u00e5r vi l\u00e6ser hver s\u00f8jle oppefra, skal vi se faserne bagfra. I det her tilf\u00e6lde kan vores overs\u00e6tter forbedre situationen, ved at flytte sidste instruktion frem. Dermed kan vi opn\u00e5 ovenst\u00e5ende udf\u00f8rsel: 01234567890 -- Beskrivelse movq (r10),r11 FDXMMW -- produce(M,r11) subq $1,r12 FDXXMW -- addq $100,r11 FDDXMW -- depend(X,r11), produce(X,r11), stall i D movq r11,(r10) FFDXMMW -- Stall i F, depend(X,r11) addq $8,r10 FDXXMW -- Forsinket F Vi kan alts\u00e5 n\u00f8jes med at benytte 11 clock perioder og f\u00e5r dermed en CPI = 11/5 = 2,2 .","title":"In-order udf\u00f8rsel af instruktioner"},{"location":"afviklingsplot/pipeline/#kontrolafhngigheder","text":"Den opm\u00e6rksomme l\u00e6ser har nok lagt m\u00e6rke til at alle tidligere programmer og mikroarkitekturer har manglet noget. Vi har endnu kun snakket om sekventielle instruktioner og ikke overvejet kontrolinstruktioner. Det skyldes at det g\u00f8r vores plots og model signifikant mere kompliceret og senere udvidelser vil faktisk g\u00f8re det nemmere. Det er derfor noget som I stadig m\u00e5 gl\u00e6de jer til.","title":"Kontrolafh\u00e6ngigheder"},{"location":"afviklingsplot/superscalar/","text":"Superskalar mikroarkitektur I jagten efter h\u00f8jere ydeevne kan man finde p\u00e5 at skrue op for ressourcerne. Hvis der er mere end en instruktion der udf\u00f8rer sin X -fase samtidigt, taler man om en superskalar maskine. Det er en naturlig f\u00f8lge af en simpel pipeline arkitektur, og de f\u00f8rste superskalar arkitekturer kom da ogs\u00e5 kort efter disse. Valget af X fasen skyldes den indsigt at denne fase er s\u00e6rligt meget brugt og ofte af instruktioner som ikke har en dataafh\u00e6ngighed. Men for at have flere instruktioner er man ogs\u00e5 n\u00f8dt til at udvide andre dele af arkitekturen. En simpel 2-vejs superskalar kan derfor h\u00e5ndtere to instruktioner samtidigt i faserne F , D , X og W , men kun 1 instruktion samtidigt i fase M . Det er motiveret af at fase M er dyrere end de andre. Tilgeng\u00e6ld kan man knytte en delm\u00e6ngde af de mulige faser til forskellige klasser af instruktioner: f.eks. det er s\u00e5ledes at ikke alle har en fase M . Vi kan derfor g\u00f8res det ved at udvide M for de instruktioner vi ved bruger M . Man kan ogs\u00e5 undg\u00e5 en fase W for instruktioner der ikke skriver til et resultat registerfilen. Eksempel: Superskalar Faser: Tilg\u00e6ngelige ressourcer: F:2 , D:2 , X:2 , M:1 , W:2 Alle faser taget har en latenstid p\u00e5 1 inorder(F,D,X,M,W) Begr\u00e6nsninger p\u00e5 instruktioner: Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b FDXW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b FDXMMW depend(X,a), produce(M,b) Skrivning movq b,(a) FDXMM depend(X,a), depend(M,b) Overvej afviklingen af f\u00f8lgende program: 01234567 -- Vigtige dataafh\u00e6ngigheder movq (r10),r11 FDXMMW -- produce(M,r11) addq $100,r11 FDDDDXW -- depend(X,r11), produce(X,r11) movq r11,(r10) FDDDXMM -- depend(M,r11) subq $8,r10 FFFFDXW -- subq $1,r12 FFFDXW -- periode: Nu kan vi indhente og afkode b\u00e5de f\u00f8rste og anden instruktion periode: Begge instruktioner flyttes til afkodning og de to n\u00e6ste bliver indhentet. Her finder vi ud af at der er en dataafh\u00e6ngighed mellem de to f\u00f8rste og sikre at anden instruktion blive stalled i D . periode: Tredje instruktion (skrivning) flyttes til afkodning, men subq bliver stalled i F , da der ikke er plads i D . periode: Sker ikke noget nyt. periode: Venter p\u00e5 l\u00e6sning periode: L\u00e6sningen er f\u00e6rdig og alle instruktioner kan flyttes frem. Skrivningen beh\u00f8ver ikke at blive stalled, da afh\u00e6ngigheden til r11 f\u00f8rst er i fase M . og 7. periode og frem forl\u00f8ber som forventet. Hvis vi igen kigger p\u00e5 s\u00f8jlerne i plottet, har ingen af disse flere forekomster af faserne end vi har ressourcer til r\u00e5dighed. Der er alts\u00e5 h\u00f8jst 2 F 'er, D 'er osv., men kun h\u00f8jest et M . Dertil ser vi at s\u00f8jlerne oppefra lister faserne bagfra og vi ved derfor at disse bliver udf\u00f8rt in-order. Hvis vi udregner CPI for denne maskine bliver den nu CPI = 8/5 = 1,6 . Dette er signifikant mindre en vores simple pipeline maskine, hvilket var CPI = 2,4 . I dette tilf\u00e6lde kan vi se at den sidste subtraktion (den vi kunne flytte frem) endda f\u00e5s gratis. Vi kan endda forvente at clock perioden for denne superskalar arkitektur er omkring det samme for vores simple pipeline; der er kun en mindre overhead for mere styring af de flere enheder.","title":"Superskalar"},{"location":"afviklingsplot/superscalar/#superskalar-mikroarkitektur","text":"I jagten efter h\u00f8jere ydeevne kan man finde p\u00e5 at skrue op for ressourcerne. Hvis der er mere end en instruktion der udf\u00f8rer sin X -fase samtidigt, taler man om en superskalar maskine. Det er en naturlig f\u00f8lge af en simpel pipeline arkitektur, og de f\u00f8rste superskalar arkitekturer kom da ogs\u00e5 kort efter disse. Valget af X fasen skyldes den indsigt at denne fase er s\u00e6rligt meget brugt og ofte af instruktioner som ikke har en dataafh\u00e6ngighed. Men for at have flere instruktioner er man ogs\u00e5 n\u00f8dt til at udvide andre dele af arkitekturen. En simpel 2-vejs superskalar kan derfor h\u00e5ndtere to instruktioner samtidigt i faserne F , D , X og W , men kun 1 instruktion samtidigt i fase M . Det er motiveret af at fase M er dyrere end de andre. Tilgeng\u00e6ld kan man knytte en delm\u00e6ngde af de mulige faser til forskellige klasser af instruktioner: f.eks. det er s\u00e5ledes at ikke alle har en fase M . Vi kan derfor g\u00f8res det ved at udvide M for de instruktioner vi ved bruger M . Man kan ogs\u00e5 undg\u00e5 en fase W for instruktioner der ikke skriver til et resultat registerfilen.","title":"Superskalar mikroarkitektur"},{"location":"afviklingsplot/superscalar/#eksempel-superskalar","text":"Faser: Tilg\u00e6ngelige ressourcer: F:2 , D:2 , X:2 , M:1 , W:2 Alle faser taget har en latenstid p\u00e5 1 inorder(F,D,X,M,W) Begr\u00e6nsninger p\u00e5 instruktioner: Instruktion Faser Dataafh\u00e6ngigheder Aritmetik op a b FDXW depend(X,a), depend(X,b), produce(X,b) L\u00e6sning movq (a),b FDXMMW depend(X,a), produce(M,b) Skrivning movq b,(a) FDXMM depend(X,a), depend(M,b) Overvej afviklingen af f\u00f8lgende program: 01234567 -- Vigtige dataafh\u00e6ngigheder movq (r10),r11 FDXMMW -- produce(M,r11) addq $100,r11 FDDDDXW -- depend(X,r11), produce(X,r11) movq r11,(r10) FDDDXMM -- depend(M,r11) subq $8,r10 FFFFDXW -- subq $1,r12 FFFDXW -- periode: Nu kan vi indhente og afkode b\u00e5de f\u00f8rste og anden instruktion periode: Begge instruktioner flyttes til afkodning og de to n\u00e6ste bliver indhentet. Her finder vi ud af at der er en dataafh\u00e6ngighed mellem de to f\u00f8rste og sikre at anden instruktion blive stalled i D . periode: Tredje instruktion (skrivning) flyttes til afkodning, men subq bliver stalled i F , da der ikke er plads i D . periode: Sker ikke noget nyt. periode: Venter p\u00e5 l\u00e6sning periode: L\u00e6sningen er f\u00e6rdig og alle instruktioner kan flyttes frem. Skrivningen beh\u00f8ver ikke at blive stalled, da afh\u00e6ngigheden til r11 f\u00f8rst er i fase M . og 7. periode og frem forl\u00f8ber som forventet. Hvis vi igen kigger p\u00e5 s\u00f8jlerne i plottet, har ingen af disse flere forekomster af faserne end vi har ressourcer til r\u00e5dighed. Der er alts\u00e5 h\u00f8jst 2 F 'er, D 'er osv., men kun h\u00f8jest et M . Dertil ser vi at s\u00f8jlerne oppefra lister faserne bagfra og vi ved derfor at disse bliver udf\u00f8rt in-order. Hvis vi udregner CPI for denne maskine bliver den nu CPI = 8/5 = 1,6 . Dette er signifikant mindre en vores simple pipeline maskine, hvilket var CPI = 2,4 . I dette tilf\u00e6lde kan vi se at den sidste subtraktion (den vi kunne flytte frem) endda f\u00e5s gratis. Vi kan endda forvente at clock perioden for denne superskalar arkitektur er omkring det samme for vores simple pipeline; der er kun en mindre overhead for mere styring af de flere enheder.","title":"Eksempel: Superskalar"}]}